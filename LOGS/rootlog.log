INFO admin 2020-07-15 16:03:41,517 - Requested to extract data.
DEBUG admin 2020-07-15 16:03:41,517 - Extracted links and ISINs from JSON object.
INFO admin 2020-07-15 16:04:01,401 - Made entry for extracted data in datafile successfully.
INFO werkzeug 2020-07-15 16:04:01,401 - 127.0.0.1 - - [15/Jul/2020 16:04:01] "[37mPOST /extract?no_of_docs=30&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:01,401 - Requested to export extracted data.
DEBUG admin 2020-07-15 16:04:01,416 - Checking if filepath has valid format
DEBUG admin 2020-07-15 16:04:01,416 - Exporting data to excel file
INFO admin 2020-07-15 16:04:01,510 - Exported successfully
INFO werkzeug 2020-07-15 16:04:01,510 - 127.0.0.1 - - [15/Jul/2020 16:04:01] "[37mPOST /extract/export?filepath=extract.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:01,526 - Requested to pre-process data.
DEBUG admin 2020-07-15 16:04:01,526 - Reading data from datafile
DEBUG admin 2020-07-15 16:04:01,557 - Pre-processing text data
DEBUG admin 2020-07-15 16:04:15,099 - Pre-processed data
DEBUG admin 2020-07-15 16:04:15,099 - Writting pre-processed data to datafile
DEBUG admin 2020-07-15 16:04:15,099 - Made entry of pre-processed data in datafile successfully
INFO werkzeug 2020-07-15 16:04:15,099 - 127.0.0.1 - - [15/Jul/2020 16:04:15] "[37mPOST /preprocess?steps=url&steps=stemming&steps=lemmatization&steps=stopwords&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:15,115 - Requested to export pre-processed data.
DEBUG admin 2020-07-15 16:04:15,115 - Reading pre-processed datafile.
DEBUG admin 2020-07-15 16:04:15,115 - Exporting pre-processed data to excel file.
INFO admin 2020-07-15 16:04:15,146 - Exported pre-processed data successfully.
INFO werkzeug 2020-07-15 16:04:15,146 - 127.0.0.1 - - [15/Jul/2020 16:04:15] "[37mPOST /preprocess/export?filepath=prep.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:15,146 - Requested to plot elbow curve.
DEBUG admin 2020-07-15 16:04:15,146 - Reading datafile..
DEBUG admin 2020-07-15 16:04:15,146 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:04:15,146 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:04:15,146 - Calculating tf-idf
DEBUG admin 2020-07-15 16:04:15,177 - Calculating variance threshold
DEBUG admin 2020-07-15 16:04:15,177 - Applying PCA
DEBUG admin 2020-07-15 16:04:15,193 - Plotting elbow curve
DEBUG admin 2020-07-15 16:04:16,974 - Writing optimal k value
INFO admin 2020-07-15 16:04:16,974 - Obtained optimal value of K using Elbow curve successfully
INFO werkzeug 2020-07-15 16:04:16,974 - 127.0.0.1 - - [15/Jul/2020 16:04:16] "[37mPOST /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:16,989 - Requested to get optimal k value
DEBUG admin 2020-07-15 16:04:16,989 - Reading datafile for optimal k value after elbow method
INFO admin 2020-07-15 16:04:16,989 - Get request for optimal k value served successfully
INFO werkzeug 2020-07-15 16:04:16,989 - 127.0.0.1 - - [15/Jul/2020 16:04:16] "[37mGET /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:16,989 - Requested for optimal value of K using Silhouette.
DEBUG admin 2020-07-15 16:04:16,989 - Reading datafile..
DEBUG admin 2020-07-15 16:04:16,989 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:04:16,989 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:04:16,989 - Calculating tf-idf
DEBUG admin 2020-07-15 16:04:17,020 - Calculating variance threshold
DEBUG admin 2020-07-15 16:04:17,020 - Applying PCA
DEBUG admin 2020-07-15 16:04:17,036 - Applying silhouette coefficient
DEBUG admin 2020-07-15 16:04:17,645 - Writting optimal k
INFO admin 2020-07-15 16:04:17,645 - Obtained optimal value of k using Silhouette score successfully
INFO werkzeug 2020-07-15 16:04:17,645 - 127.0.0.1 - - [15/Jul/2020 16:04:17] "[37mPOST /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:17,661 - Requested to get optimal k value
DEBUG admin 2020-07-15 16:04:17,661 - Reading datafile for optimal k value after silhouette
INFO admin 2020-07-15 16:04:17,661 - Get request for optimal k value served successfully
INFO werkzeug 2020-07-15 16:04:17,661 - 127.0.0.1 - - [15/Jul/2020 16:04:17] "[37mGET /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:17,661 - Requested to cluster documents.
DEBUG admin 2020-07-15 16:04:17,661 - Reading datafile..
DEBUG admin 2020-07-15 16:04:17,661 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:04:17,661 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:04:17,661 - Calculating tf-idf
DEBUG admin 2020-07-15 16:04:17,692 - Calculating variance threshold
DEBUG admin 2020-07-15 16:04:17,692 - Applying PCA
DEBUG admin 2020-07-15 16:04:17,708 - Applying K-Means algorithm
DEBUG admin 2020-07-15 16:04:17,739 - Sorting clusters
DEBUG admin 2020-07-15 16:04:17,739 - Converting to JSON format
DEBUG admin 2020-07-15 16:04:17,739 - Writting summary
DEBUG admin 2020-07-15 16:04:17,739 - Writting clustering information to datafile
INFO werkzeug 2020-07-15 16:04:17,739 - 127.0.0.1 - - [15/Jul/2020 16:04:17] "[37mPOST /clustering/kmeans?k=4&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:17,739 - Requested to get clustering details.
DEBUG admin 2020-07-15 16:04:17,739 - Reading datafile for clustered data
INFO admin 2020-07-15 16:04:17,739 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 16:04:17,739 - 127.0.0.1 - - [15/Jul/2020 16:04:17] "[37mGET /clustering/kmeans?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:17,755 - Requested to get clustering summary.
DEBUG admin 2020-07-15 16:04:17,755 - Reading datafile for clustering summary
INFO admin 2020-07-15 16:04:17,755 - Get request for clustering summary served successfully
DEBUG admin 2020-07-15 16:04:17,755 - Returning summary
INFO werkzeug 2020-07-15 16:04:17,755 - 127.0.0.1 - - [15/Jul/2020 16:04:17] "[37mGET /clustering/summary?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:17,755 - Requested to cluster documents.
DEBUG admin 2020-07-15 16:04:17,755 - Reading datafile..
DEBUG admin 2020-07-15 16:04:17,755 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:04:17,755 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:04:17,770 - Calculating tf-idf
DEBUG admin 2020-07-15 16:04:17,786 - Calculating variance threshold
DEBUG admin 2020-07-15 16:04:17,802 - Applying PCA
DEBUG admin 2020-07-15 16:04:17,802 - Applying DBSCAN algorithm
DEBUG admin 2020-07-15 16:04:17,864 - Sorting clusters
DEBUG admin 2020-07-15 16:04:17,864 - Converting to JSON format
DEBUG admin 2020-07-15 16:04:17,864 - Writting summary
DEBUG admin 2020-07-15 16:04:17,864 - Writting clustering information to datafile
INFO werkzeug 2020-07-15 16:04:17,880 - 127.0.0.1 - - [15/Jul/2020 16:04:17] "[37mPOST /clustering/dbscan?eps=0.3&min=1&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:17,880 - Requested to get clustering details.
DEBUG admin 2020-07-15 16:04:17,880 - Reading datafile for clustered data
INFO admin 2020-07-15 16:04:17,880 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 16:04:17,880 - 127.0.0.1 - - [15/Jul/2020 16:04:17] "[37mGET /clustering/dbscan?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:17,895 - Requested to get clustering summary.
DEBUG admin 2020-07-15 16:04:17,895 - Reading datafile for clustering summary
INFO admin 2020-07-15 16:04:17,895 - Get request for clustering summary served successfully
DEBUG admin 2020-07-15 16:04:17,895 - Returning summary
INFO werkzeug 2020-07-15 16:04:17,895 - 127.0.0.1 - - [15/Jul/2020 16:04:17] "[37mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:17,895 - Requested to cluster documents.
DEBUG admin 2020-07-15 16:04:17,895 - Reading datafile..
DEBUG admin 2020-07-15 16:04:17,895 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:04:17,895 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:04:17,895 - Calculating tf-idf
DEBUG admin 2020-07-15 16:04:17,926 - Calculating variance threshold
DEBUG admin 2020-07-15 16:04:17,926 - Applying PCA
DEBUG admin 2020-07-15 16:04:17,942 - Applying Agglomerative algorithm
DEBUG admin 2020-07-15 16:04:18,005 - Sorting clusters
DEBUG admin 2020-07-15 16:04:18,005 - Converting to JSON format
DEBUG admin 2020-07-15 16:04:18,005 - Writting summary
DEBUG admin 2020-07-15 16:04:18,005 - Writting clustering information to datafile
INFO werkzeug 2020-07-15 16:04:18,020 - 127.0.0.1 - - [15/Jul/2020 16:04:18] "[37mPOST /clustering/agglomerative?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:18,020 - Requested to get clustering details.
DEBUG admin 2020-07-15 16:04:18,020 - Reading datafile for clustered data
INFO admin 2020-07-15 16:04:18,020 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 16:04:18,020 - 127.0.0.1 - - [15/Jul/2020 16:04:18] "[37mGET /clustering/agglomerative?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:18,036 - Requested to get clustering summary.
DEBUG admin 2020-07-15 16:04:18,036 - Reading datafile for clustering summary
INFO admin 2020-07-15 16:04:18,036 - Get request for clustering summary served successfully
DEBUG admin 2020-07-15 16:04:18,036 - Returning summary
INFO werkzeug 2020-07-15 16:04:18,036 - 127.0.0.1 - - [15/Jul/2020 16:04:18] "[37mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:18,036 - Requested to cluster documents.
DEBUG admin 2020-07-15 16:04:18,036 - Reading datafile..
DEBUG admin 2020-07-15 16:04:18,036 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:04:18,036 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:04:18,036 - Calculating tf-idf
DEBUG admin 2020-07-15 16:04:18,067 - Calculating variance threshold
DEBUG admin 2020-07-15 16:04:18,067 - Applying PCA
DEBUG admin 2020-07-15 16:04:18,083 - Applying Birch algorithm
DEBUG admin 2020-07-15 16:04:18,114 - Sorting clusters
DEBUG admin 2020-07-15 16:04:18,114 - Converting to JSON format
DEBUG admin 2020-07-15 16:04:18,114 - Writting summary
DEBUG admin 2020-07-15 16:04:18,114 - Writting clustering information to datafile
INFO werkzeug 2020-07-15 16:04:18,114 - 127.0.0.1 - - [15/Jul/2020 16:04:18] "[37mPOST /clustering/birch?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:18,114 - Requested to get clustering details.
DEBUG admin 2020-07-15 16:04:18,114 - Reading datafile for clustered data
INFO admin 2020-07-15 16:04:18,114 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 16:04:18,114 - 127.0.0.1 - - [15/Jul/2020 16:04:18] "[37mGET /clustering/birch?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:18,130 - Requested to get clustering summary.
DEBUG admin 2020-07-15 16:04:18,130 - Reading datafile for clustering summary
INFO admin 2020-07-15 16:04:18,130 - Get request for clustering summary served successfully
DEBUG admin 2020-07-15 16:04:18,130 - Returning summary
INFO werkzeug 2020-07-15 16:04:18,130 - 127.0.0.1 - - [15/Jul/2020 16:04:18] "[37mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:18,130 - Logging off...deleting all cached files
INFO admin 2020-07-15 16:04:18,145 - Cleared cache
INFO werkzeug 2020-07-15 16:04:18,145 - 127.0.0.1 - - [15/Jul/2020 16:04:18] "[37mDELETE /clear?uname=admin HTTP/1.1[0m" 200 -
INFO abcd 2020-07-15 16:04:18,145 - Requested for report generation.
DEBUG abcd 2020-07-15 16:04:18,145 - Checking for json input
DEBUG abcd 2020-07-15 16:04:18,145 - Fetching URLs
DEBUG abcd 2020-07-15 16:04:18,145 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007930/dp108304_424b2-us1972721.htm URL
DEBUG abcd 2020-07-15 16:04:22,641 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008018/dp108385_424b2-us1972668.htm URL
DEBUG abcd 2020-07-15 16:04:23,141 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008084/dp108463_424b2-us1972667.htm URL
DEBUG abcd 2020-07-15 16:04:23,640 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009058/dp109430_424b2-us1972617.htm URL
DEBUG abcd 2020-07-15 16:04:24,127 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007911/dp108280_424b2-us1972550.htm URL
DEBUG abcd 2020-07-15 16:04:24,658 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009050/dp109447_424b2-us1972547.htm URL
DEBUG abcd 2020-07-15 16:04:25,190 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007828/dp108206_424b2-us1972545.htm URL
DEBUG abcd 2020-07-15 16:04:25,736 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009060/dp109497_424b2-us1972484.htm URL
DEBUG abcd 2020-07-15 16:04:26,392 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007527/dp107872_fwp-us1972482.htm URL
DEBUG abcd 2020-07-15 16:04:26,674 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007524/dp107870_fwp-us1972480.htm URL
DEBUG abcd 2020-07-15 16:04:26,954 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008572/dp109026_424b2-us1972369.htm URL
DEBUG abcd 2020-07-15 16:04:27,502 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007525/dp107868_fwp-us1972350.htm URL
DEBUG abcd 2020-07-15 16:04:27,783 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009080/dp109492_424b2-us1972281.htm URL
DEBUG abcd 2020-07-15 16:04:28,579 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007870/dp108232_424b2-us1972280.htm URL
DEBUG abcd 2020-07-15 16:04:29,626 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007155/dp107611_424b2-us1972269.htm URL
DEBUG abcd 2020-07-15 16:04:30,236 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009048/dp109444_424b2-us1972158.htm URL
INFO abcd 2020-07-15 16:04:30,798 - Report generation has started.
DEBUG abcd 2020-07-15 16:04:30,798 - Using bruteforce method for report generation
INFO werkzeug 2020-07-15 16:04:30,798 - 127.0.0.1 - - [15/Jul/2020 16:04:30] "[37mPOST /report?uname=abcd&kind=1 HTTP/1.1[0m" 200 -
INFO abcd 2020-07-15 16:04:30,829 - Requested for report generation.
DEBUG abcd 2020-07-15 16:04:30,829 - Searching for JSON Dump
ERROR abcd 2020-07-15 16:04:30,829 - Could not find the JSON Dump, the file is not prepared yet
INFO werkzeug 2020-07-15 16:04:30,829 - 127.0.0.1 - - [15/Jul/2020 16:04:30] "[31m[1mGET /report?uname=abcd HTTP/1.1[0m" 400 -
INFO admin 2020-07-15 16:04:30,845 - Requested to get log file..
INFO admin 2020-07-15 16:04:30,845 - Sending log file
INFO werkzeug 2020-07-15 16:04:30,845 - 127.0.0.1 - - [15/Jul/2020 16:04:30] "[37mGET /getlog?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:04:30,845 - Requested to clear log file..
INFO admin 2020-07-15 16:04:30,860 - Cleared log file
INFO werkzeug 2020-07-15 16:04:30,860 - 127.0.0.1 - - [15/Jul/2020 16:04:30] "[37mDELETE /clearlog?uname=admin HTTP/1.1[0m" 200 -
INFO abcd 2020-07-15 16:04:32,532 - Report generated successfully
INFO admin 2020-07-15 16:05:29,253 - Requested to extract data.
DEBUG admin 2020-07-15 16:05:29,253 - Extracted links and ISINs from JSON object.
INFO admin 2020-07-15 16:05:53,210 - Made entry for extracted data in datafile successfully.
INFO werkzeug 2020-07-15 16:05:53,210 - 127.0.0.1 - - [15/Jul/2020 16:05:53] "[37mPOST /extract?no_of_docs=30&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:05:53,210 - Requested to export extracted data.
DEBUG admin 2020-07-15 16:05:53,225 - Checking if filepath has valid format
DEBUG admin 2020-07-15 16:05:53,225 - Exporting data to excel file
INFO admin 2020-07-15 16:05:53,335 - Exported successfully
INFO werkzeug 2020-07-15 16:05:53,335 - 127.0.0.1 - - [15/Jul/2020 16:05:53] "[37mPOST /extract/export?filepath=extract.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:05:53,335 - Requested to pre-process data.
DEBUG admin 2020-07-15 16:05:53,350 - Reading data from datafile
DEBUG admin 2020-07-15 16:05:53,350 - Pre-processing text data
DEBUG admin 2020-07-15 16:06:05,334 - Pre-processed data
DEBUG admin 2020-07-15 16:06:05,334 - Writting pre-processed data to datafile
DEBUG admin 2020-07-15 16:06:05,334 - Made entry of pre-processed data in datafile successfully
INFO werkzeug 2020-07-15 16:06:05,334 - 127.0.0.1 - - [15/Jul/2020 16:06:05] "[37mPOST /preprocess?steps=url&steps=stemming&steps=lemmatization&steps=stopwords&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:05,334 - Requested to export pre-processed data.
DEBUG admin 2020-07-15 16:06:05,334 - Reading pre-processed datafile.
DEBUG admin 2020-07-15 16:06:05,334 - Exporting pre-processed data to excel file.
INFO admin 2020-07-15 16:06:05,459 - Exported pre-processed data successfully.
INFO werkzeug 2020-07-15 16:06:05,459 - 127.0.0.1 - - [15/Jul/2020 16:06:05] "[37mPOST /preprocess/export?filepath=prep.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:05,459 - Requested to plot elbow curve.
DEBUG admin 2020-07-15 16:06:05,459 - Reading datafile..
DEBUG admin 2020-07-15 16:06:05,459 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:06:05,459 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:06:05,459 - Calculating tf-idf
DEBUG admin 2020-07-15 16:06:05,490 - Calculating variance threshold
DEBUG admin 2020-07-15 16:06:05,490 - Applying PCA
DEBUG admin 2020-07-15 16:06:05,506 - Plotting elbow curve
DEBUG admin 2020-07-15 16:06:07,239 - Writing optimal k value
INFO admin 2020-07-15 16:06:07,239 - Obtained optimal value of K using Elbow curve successfully
INFO werkzeug 2020-07-15 16:06:07,239 - 127.0.0.1 - - [15/Jul/2020 16:06:07] "[37mPOST /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:07,255 - Requested to get optimal k value
DEBUG admin 2020-07-15 16:06:07,255 - Reading datafile for optimal k value after elbow method
INFO admin 2020-07-15 16:06:07,255 - Get request for optimal k value served successfully
INFO werkzeug 2020-07-15 16:06:07,255 - 127.0.0.1 - - [15/Jul/2020 16:06:07] "[37mGET /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:07,255 - Requested for optimal value of K using Silhouette.
DEBUG admin 2020-07-15 16:06:07,255 - Reading datafile..
DEBUG admin 2020-07-15 16:06:07,255 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:06:07,255 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:06:07,255 - Calculating tf-idf
DEBUG admin 2020-07-15 16:06:07,286 - Calculating variance threshold
DEBUG admin 2020-07-15 16:06:07,286 - Applying PCA
DEBUG admin 2020-07-15 16:06:07,302 - Applying silhouette coefficient
DEBUG admin 2020-07-15 16:06:07,927 - Writting optimal k
INFO admin 2020-07-15 16:06:07,927 - Obtained optimal value of k using Silhouette score successfully
INFO werkzeug 2020-07-15 16:06:07,927 - 127.0.0.1 - - [15/Jul/2020 16:06:07] "[37mPOST /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:07,927 - Requested to get optimal k value
DEBUG admin 2020-07-15 16:06:07,927 - Reading datafile for optimal k value after silhouette
INFO admin 2020-07-15 16:06:07,927 - Get request for optimal k value served successfully
INFO werkzeug 2020-07-15 16:06:07,927 - 127.0.0.1 - - [15/Jul/2020 16:06:07] "[37mGET /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:07,942 - Requested to cluster documents.
DEBUG admin 2020-07-15 16:06:07,942 - Reading datafile..
DEBUG admin 2020-07-15 16:06:07,942 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:06:07,942 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:06:07,942 - Calculating tf-idf
DEBUG admin 2020-07-15 16:06:07,958 - Calculating variance threshold
DEBUG admin 2020-07-15 16:06:07,974 - Applying PCA
DEBUG admin 2020-07-15 16:06:07,974 - Applying K-Means algorithm
DEBUG admin 2020-07-15 16:06:08,005 - Sorting clusters
DEBUG admin 2020-07-15 16:06:08,005 - Converting to JSON format
DEBUG admin 2020-07-15 16:06:08,005 - Writting summary
DEBUG admin 2020-07-15 16:06:08,005 - Writting clustering information to datafile
INFO werkzeug 2020-07-15 16:06:08,005 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mPOST /clustering/kmeans?k=4&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:08,005 - Requested to get clustering details.
DEBUG admin 2020-07-15 16:06:08,005 - Reading datafile for clustered data
INFO admin 2020-07-15 16:06:08,021 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 16:06:08,021 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mGET /clustering/kmeans?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:08,021 - Requested to get clustering summary.
DEBUG admin 2020-07-15 16:06:08,021 - Reading datafile for clustering summary
INFO admin 2020-07-15 16:06:08,021 - Get request for clustering summary served successfully
DEBUG admin 2020-07-15 16:06:08,021 - Returning summary
INFO werkzeug 2020-07-15 16:06:08,021 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mGET /clustering/summary?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:08,036 - Requested to cluster documents.
DEBUG admin 2020-07-15 16:06:08,036 - Reading datafile..
DEBUG admin 2020-07-15 16:06:08,036 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:06:08,036 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:06:08,036 - Calculating tf-idf
DEBUG admin 2020-07-15 16:06:08,067 - Calculating variance threshold
DEBUG admin 2020-07-15 16:06:08,067 - Applying PCA
DEBUG admin 2020-07-15 16:06:08,083 - Applying DBSCAN algorithm
DEBUG admin 2020-07-15 16:06:08,083 - Sorting clusters
DEBUG admin 2020-07-15 16:06:08,083 - Converting to JSON format
DEBUG admin 2020-07-15 16:06:08,083 - Writting summary
DEBUG admin 2020-07-15 16:06:08,083 - Writting clustering information to datafile
INFO werkzeug 2020-07-15 16:06:08,083 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mPOST /clustering/dbscan?eps=0.3&min=1&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:08,099 - Requested to get clustering details.
DEBUG admin 2020-07-15 16:06:08,099 - Reading datafile for clustered data
INFO admin 2020-07-15 16:06:08,099 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 16:06:08,099 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mGET /clustering/dbscan?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:08,099 - Requested to get clustering summary.
DEBUG admin 2020-07-15 16:06:08,099 - Reading datafile for clustering summary
INFO admin 2020-07-15 16:06:08,099 - Get request for clustering summary served successfully
DEBUG admin 2020-07-15 16:06:08,114 - Returning summary
INFO werkzeug 2020-07-15 16:06:08,114 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:08,114 - Requested to cluster documents.
DEBUG admin 2020-07-15 16:06:08,114 - Reading datafile..
DEBUG admin 2020-07-15 16:06:08,114 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:06:08,114 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:06:08,114 - Calculating tf-idf
DEBUG admin 2020-07-15 16:06:08,146 - Calculating variance threshold
DEBUG admin 2020-07-15 16:06:08,146 - Applying PCA
DEBUG admin 2020-07-15 16:06:08,161 - Applying Agglomerative algorithm
DEBUG admin 2020-07-15 16:06:08,161 - Sorting clusters
DEBUG admin 2020-07-15 16:06:08,161 - Converting to JSON format
DEBUG admin 2020-07-15 16:06:08,161 - Writting summary
DEBUG admin 2020-07-15 16:06:08,161 - Writting clustering information to datafile
INFO werkzeug 2020-07-15 16:06:08,177 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mPOST /clustering/agglomerative?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:08,177 - Requested to get clustering details.
DEBUG admin 2020-07-15 16:06:08,177 - Reading datafile for clustered data
INFO admin 2020-07-15 16:06:08,177 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 16:06:08,177 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mGET /clustering/agglomerative?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:08,192 - Requested to get clustering summary.
DEBUG admin 2020-07-15 16:06:08,192 - Reading datafile for clustering summary
INFO admin 2020-07-15 16:06:08,192 - Get request for clustering summary served successfully
DEBUG admin 2020-07-15 16:06:08,192 - Returning summary
INFO werkzeug 2020-07-15 16:06:08,192 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:08,192 - Requested to cluster documents.
DEBUG admin 2020-07-15 16:06:08,192 - Reading datafile..
DEBUG admin 2020-07-15 16:06:08,192 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 16:06:08,192 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 16:06:08,192 - Calculating tf-idf
DEBUG admin 2020-07-15 16:06:08,224 - Calculating variance threshold
DEBUG admin 2020-07-15 16:06:08,224 - Applying PCA
DEBUG admin 2020-07-15 16:06:08,239 - Applying Birch algorithm
DEBUG admin 2020-07-15 16:06:08,239 - Sorting clusters
DEBUG admin 2020-07-15 16:06:08,255 - Converting to JSON format
DEBUG admin 2020-07-15 16:06:08,255 - Writting summary
DEBUG admin 2020-07-15 16:06:08,255 - Writting clustering information to datafile
INFO werkzeug 2020-07-15 16:06:08,255 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mPOST /clustering/birch?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:08,255 - Requested to get clustering details.
DEBUG admin 2020-07-15 16:06:08,255 - Reading datafile for clustered data
INFO admin 2020-07-15 16:06:08,255 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 16:06:08,255 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mGET /clustering/birch?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:08,270 - Requested to get clustering summary.
DEBUG admin 2020-07-15 16:06:08,270 - Reading datafile for clustering summary
INFO admin 2020-07-15 16:06:08,270 - Get request for clustering summary served successfully
DEBUG admin 2020-07-15 16:06:08,270 - Returning summary
INFO werkzeug 2020-07-15 16:06:08,270 - 127.0.0.1 - - [15/Jul/2020 16:06:08] "[37mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO abcd 2020-07-15 16:06:08,270 - Requested for report generation.
INFO abcd 2020-07-15 16:06:08,270 - Older JSON Dump for abcd has been deleted
DEBUG abcd 2020-07-15 16:06:08,270 - Checking for json input
DEBUG abcd 2020-07-15 16:06:08,270 - Fetching URLs
DEBUG abcd 2020-07-15 16:06:08,270 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007930/dp108304_424b2-us1972721.htm URL
DEBUG abcd 2020-07-15 16:06:09,333 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008018/dp108385_424b2-us1972668.htm URL
DEBUG abcd 2020-07-15 16:06:09,952 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008084/dp108463_424b2-us1972667.htm URL
DEBUG abcd 2020-07-15 16:06:10,436 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009058/dp109430_424b2-us1972617.htm URL
DEBUG abcd 2020-07-15 16:06:10,920 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007911/dp108280_424b2-us1972550.htm URL
DEBUG abcd 2020-07-15 16:06:11,425 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009050/dp109447_424b2-us1972547.htm URL
DEBUG abcd 2020-07-15 16:06:11,893 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007828/dp108206_424b2-us1972545.htm URL
DEBUG abcd 2020-07-15 16:06:12,408 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009060/dp109497_424b2-us1972484.htm URL
DEBUG abcd 2020-07-15 16:06:12,971 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007527/dp107872_fwp-us1972482.htm URL
DEBUG abcd 2020-07-15 16:06:13,283 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007524/dp107870_fwp-us1972480.htm URL
DEBUG abcd 2020-07-15 16:06:13,564 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008572/dp109026_424b2-us1972369.htm URL
DEBUG abcd 2020-07-15 16:06:14,096 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007525/dp107868_fwp-us1972350.htm URL
DEBUG abcd 2020-07-15 16:06:14,391 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009080/dp109492_424b2-us1972281.htm URL
DEBUG abcd 2020-07-15 16:06:15,109 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007870/dp108232_424b2-us1972280.htm URL
DEBUG abcd 2020-07-15 16:06:15,749 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007155/dp107611_424b2-us1972269.htm URL
DEBUG abcd 2020-07-15 16:06:16,203 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009048/dp109444_424b2-us1972158.htm URL
INFO abcd 2020-07-15 16:06:16,715 - Report generation has started.
DEBUG abcd 2020-07-15 16:06:16,715 - Using bruteforce method for report generation
INFO werkzeug 2020-07-15 16:06:16,715 - 127.0.0.1 - - [15/Jul/2020 16:06:16] "[37mPOST /report?uname=abcd&kind=1 HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:16,715 - Requested to get log file..
INFO admin 2020-07-15 16:06:16,715 - Sending log file
INFO werkzeug 2020-07-15 16:06:16,715 - 127.0.0.1 - - [15/Jul/2020 16:06:16] "[37mGET /getlog?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:06:16,730 - Requested to clear log file..
INFO admin 2020-07-15 16:06:16,730 - Cleared log file
INFO werkzeug 2020-07-15 16:06:16,730 - 127.0.0.1 - - [15/Jul/2020 16:06:16] "[37mDELETE /clearlog?uname=admin HTTP/1.1[0m" 200 -
INFO abcd 2020-07-15 16:06:18,542 - Report generated successfully
INFO abcd 2020-07-15 16:06:42,728 - Requested for report generation.
DEBUG abcd 2020-07-15 16:06:42,728 - Searching for JSON Dump
DEBUG abcd 2020-07-15 16:06:42,728 - Found JSON Dump
DEBUG abcd 2020-07-15 16:06:42,728 - Get request served successfully
INFO werkzeug 2020-07-15 16:06:42,728 - 127.0.0.1 - - [15/Jul/2020 16:06:42] "[37mGET /report?uname=abcd HTTP/1.1[0m" 200 -
INFO werkzeug 2020-07-15 16:21:24,481 - 127.0.0.1 - - [15/Jul/2020 16:21:24] "[37mGET / HTTP/1.1[0m" 200 -
INFO werkzeug 2020-07-15 16:21:24,709 - 127.0.0.1 - - [15/Jul/2020 16:21:24] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
INFO admin 2020-07-15 16:29:33,521 - Requested to extract data.
DEBUG admin 2020-07-15 16:29:33,521 - Extracted links and ISINs from JSON object.
DEBUG admin 2020-07-15 16:29:33,521 - Extracting all documents.
INFO admin 2020-07-15 16:46:16,615 - Requested to extract data.
DEBUG admin 2020-07-15 16:46:16,615 - Extracted links and ISINs from JSON object.
DEBUG admin 2020-07-15 16:46:16,615 - Extracting all documents.
INFO admin 2020-07-15 16:54:36,565 - Requested to extract data.
DEBUG admin 2020-07-15 16:54:36,565 - Extracted links and ISINs from JSON object.
INFO admin 2020-07-15 16:58:36,155 - Made entry for extracted data in datafile successfully.
INFO werkzeug 2020-07-15 16:58:36,155 - 127.0.0.1 - - [15/Jul/2020 16:58:36] "[37mPOST /extract?uname=admin&fname=ISINS_v3.xlsx&no_of_docs=500 HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:58:36,171 - Requested to export extracted data.
DEBUG admin 2020-07-15 16:58:36,379 - Checking if filepath has valid format
DEBUG admin 2020-07-15 16:58:36,379 - Exporting data to excel file
INFO admin 2020-07-15 16:58:39,182 - Exported successfully
INFO werkzeug 2020-07-15 16:58:39,190 - 127.0.0.1 - - [15/Jul/2020 16:58:39] "[37mPOST /extract/export?filepath=extract.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 16:59:56,196 - Requested to pre-process data.
DEBUG admin 2020-07-15 16:59:56,196 - Reading data from datafile
DEBUG admin 2020-07-15 16:59:56,540 - Pre-processing text data
DEBUG admin 2020-07-15 17:08:38,017 - Pre-processed data
DEBUG admin 2020-07-15 17:08:38,017 - Writting pre-processed data to datafile
DEBUG admin 2020-07-15 17:08:38,057 - Made entry of pre-processed data in datafile successfully
INFO werkzeug 2020-07-15 17:08:38,067 - 127.0.0.1 - - [15/Jul/2020 17:08:38] "[37mPOST /preprocess?steps=stemming&steps=lemmatization&steps=stopwords&steps=url&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 17:08:38,081 - Requested to get pre-processed data.
DEBUG admin 2020-07-15 17:08:38,081 - Reading pre-processed datafile
INFO admin 2020-07-15 17:08:38,081 - Get request for pre-processed data served successfully
INFO werkzeug 2020-07-15 17:08:38,116 - 127.0.0.1 - - [15/Jul/2020 17:08:38] "[37mGET /preprocess?steps=stemming&steps=lemmatization&steps=stopwords&steps=url&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 17:12:29,411 - Requested to plot elbow curve.
DEBUG admin 2020-07-15 17:12:29,411 - Reading datafile..
DEBUG admin 2020-07-15 17:12:29,427 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 17:12:29,427 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 17:12:29,427 - Calculating tf-idf
DEBUG admin 2020-07-15 17:12:29,802 - Calculating variance threshold
DEBUG admin 2020-07-15 17:12:29,818 - Applying PCA
DEBUG admin 2020-07-15 17:12:30,692 - Plotting elbow curve
DEBUG admin 2020-07-15 17:13:02,816 - Writing optimal k value
INFO admin 2020-07-15 17:13:02,821 - Obtained optimal value of K using Elbow curve successfully
INFO werkzeug 2020-07-15 17:13:02,827 - 127.0.0.1 - - [15/Jul/2020 17:13:02] "[37mPOST /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 17:13:02,847 - Requested to get optimal k value
DEBUG admin 2020-07-15 17:13:02,847 - Reading datafile for optimal k value after elbow method
INFO admin 2020-07-15 17:13:02,847 - Get request for optimal k value served successfully
INFO werkzeug 2020-07-15 17:13:02,847 - 127.0.0.1 - - [15/Jul/2020 17:13:02] "[37mGET /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 17:13:02,867 - Requested for optimal value of K using Silhouette.
DEBUG admin 2020-07-15 17:13:02,867 - Reading datafile..
DEBUG admin 2020-07-15 17:13:02,881 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 17:13:02,881 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 17:13:02,881 - Calculating tf-idf
DEBUG admin 2020-07-15 17:13:03,387 - Calculating variance threshold
DEBUG admin 2020-07-15 17:13:03,417 - Applying PCA
DEBUG admin 2020-07-15 17:13:04,197 - Applying silhouette coefficient
DEBUG admin 2020-07-15 17:13:11,420 - Writting optimal k
INFO admin 2020-07-15 17:13:11,420 - Obtained optimal value of k using Silhouette score successfully
INFO werkzeug 2020-07-15 17:13:11,420 - 127.0.0.1 - - [15/Jul/2020 17:13:11] "[37mPOST /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 17:13:11,436 - Requested to get optimal k value
DEBUG admin 2020-07-15 17:13:11,436 - Reading datafile for optimal k value after silhouette
INFO admin 2020-07-15 17:13:11,436 - Get request for optimal k value served successfully
INFO werkzeug 2020-07-15 17:13:11,452 - 127.0.0.1 - - [15/Jul/2020 17:13:11] "[37mGET /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 17:14:18,359 - Requested to cluster documents.
DEBUG admin 2020-07-15 17:14:18,359 - Reading datafile..
DEBUG admin 2020-07-15 17:14:18,375 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 17:14:18,375 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 17:14:18,375 - Calculating tf-idf
DEBUG admin 2020-07-15 17:14:18,734 - Calculating variance threshold
DEBUG admin 2020-07-15 17:14:18,765 - Applying PCA
DEBUG admin 2020-07-15 17:14:19,265 - Applying K-Means algorithm
DEBUG admin 2020-07-15 17:14:19,562 - Sorting clusters
DEBUG admin 2020-07-15 17:14:19,562 - Converting to JSON format
DEBUG admin 2020-07-15 17:14:19,578 - Writting summary
DEBUG admin 2020-07-15 17:14:19,578 - Writting clustering information to datafile
INFO werkzeug 2020-07-15 17:14:19,578 - 127.0.0.1 - - [15/Jul/2020 17:14:19] "[37mPOST /clustering/kmeans?k=45&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 17:15:25,523 - Requested to get clustering details.
DEBUG admin 2020-07-15 17:15:25,523 - Reading datafile for clustered data
INFO admin 2020-07-15 17:15:25,523 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 17:15:25,523 - 127.0.0.1 - - [15/Jul/2020 17:15:25] "[37mGET /clustering/kmeans?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 17:43:27,125 - Requested to extract data.
DEBUG admin 2020-07-15 17:43:27,125 - Extracted links and ISINs from JSON object.
INFO admin 2020-07-15 17:50:09,470 - Made entry for extracted data in datafile successfully.
INFO werkzeug 2020-07-15 17:50:09,478 - 127.0.0.1 - - [15/Jul/2020 17:50:09] "[37mPOST /extract?uname=admin&fname=ISINS_v3.xlsx&no_of_docs=500 HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 17:50:09,494 - Requested to export extracted data.
DEBUG admin 2020-07-15 17:50:09,814 - Checking if filepath has valid format
DEBUG admin 2020-07-15 17:50:09,814 - Exporting data to excel file
INFO admin 2020-07-15 17:50:12,712 - Exported successfully
INFO werkzeug 2020-07-15 17:50:12,720 - 127.0.0.1 - - [15/Jul/2020 17:50:12] "[37mPOST /extract/export?filepath=extract.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 17:51:33,986 - Requested to pre-process data.
DEBUG admin 2020-07-15 17:51:33,986 - Reading data from datafile
DEBUG admin 2020-07-15 17:51:34,314 - Pre-processing text data
DEBUG admin 2020-07-15 18:00:47,085 - Pre-processed data
DEBUG admin 2020-07-15 18:00:47,085 - Writting pre-processed data to datafile
DEBUG admin 2020-07-15 18:00:47,120 - Made entry of pre-processed data in datafile successfully
INFO werkzeug 2020-07-15 18:00:47,130 - 127.0.0.1 - - [15/Jul/2020 18:00:47] "[37mPOST /preprocess?steps=stemming&steps=lemmatization&steps=stopwords&steps=url&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 18:00:47,145 - Requested to get pre-processed data.
DEBUG admin 2020-07-15 18:00:47,145 - Reading pre-processed datafile
INFO admin 2020-07-15 18:00:47,145 - Get request for pre-processed data served successfully
INFO werkzeug 2020-07-15 18:00:47,175 - 127.0.0.1 - - [15/Jul/2020 18:00:47] "[37mGET /preprocess?steps=stemming&steps=lemmatization&steps=stopwords&steps=url&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 18:01:54,851 - Requested to plot elbow curve.
DEBUG admin 2020-07-15 18:01:54,851 - Reading datafile..
DEBUG admin 2020-07-15 18:01:54,861 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 18:01:54,861 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 18:01:54,861 - Calculating tf-idf
DEBUG admin 2020-07-15 18:01:55,539 - Calculating variance threshold
DEBUG admin 2020-07-15 18:01:55,579 - Applying PCA
DEBUG admin 2020-07-15 18:01:56,448 - Plotting elbow curve
DEBUG admin 2020-07-15 18:02:36,599 - Writing optimal k value
INFO admin 2020-07-15 18:02:36,599 - Obtained optimal value of K using Elbow curve successfully
INFO werkzeug 2020-07-15 18:02:36,607 - 127.0.0.1 - - [15/Jul/2020 18:02:36] "[37mPOST /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 18:02:36,623 - Requested to get optimal k value
DEBUG admin 2020-07-15 18:02:36,631 - Reading datafile for optimal k value after elbow method
INFO admin 2020-07-15 18:02:36,631 - Get request for optimal k value served successfully
INFO werkzeug 2020-07-15 18:02:36,631 - 127.0.0.1 - - [15/Jul/2020 18:02:36] "[37mGET /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 18:02:36,639 - Requested for optimal value of K using Silhouette.
DEBUG admin 2020-07-15 18:02:36,639 - Reading datafile..
DEBUG admin 2020-07-15 18:02:36,655 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 18:02:36,655 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 18:02:36,655 - Calculating tf-idf
DEBUG admin 2020-07-15 18:02:37,364 - Calculating variance threshold
DEBUG admin 2020-07-15 18:02:37,404 - Applying PCA
DEBUG admin 2020-07-15 18:02:38,346 - Applying silhouette coefficient
DEBUG admin 2020-07-15 18:02:47,087 - Writting optimal k
INFO admin 2020-07-15 18:02:47,095 - Obtained optimal value of k using Silhouette score successfully
INFO werkzeug 2020-07-15 18:02:47,095 - 127.0.0.1 - - [15/Jul/2020 18:02:47] "[37mPOST /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 18:02:47,111 - Requested to get optimal k value
DEBUG admin 2020-07-15 18:02:47,111 - Reading datafile for optimal k value after silhouette
INFO admin 2020-07-15 18:02:47,111 - Get request for optimal k value served successfully
INFO werkzeug 2020-07-15 18:02:47,111 - 127.0.0.1 - - [15/Jul/2020 18:02:47] "[37mGET /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 18:02:47,127 - Requested to cluster documents.
DEBUG admin 2020-07-15 18:02:47,127 - Reading datafile..
DEBUG admin 2020-07-15 18:02:47,143 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 18:02:47,151 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 18:02:47,151 - Calculating tf-idf
DEBUG admin 2020-07-15 18:02:47,780 - Calculating variance threshold
DEBUG admin 2020-07-15 18:02:47,860 - Applying PCA
DEBUG admin 2020-07-15 18:02:48,828 - Applying K-Means algorithm
DEBUG admin 2020-07-15 18:02:49,370 - Sorting clusters
DEBUG admin 2020-07-15 18:02:49,370 - Converting to JSON format
DEBUG admin 2020-07-15 18:02:49,394 - Writting summary
DEBUG admin 2020-07-15 18:02:49,394 - Writting clustering information to datafile
INFO werkzeug 2020-07-15 18:02:49,418 - 127.0.0.1 - - [15/Jul/2020 18:02:49] "[37mPOST /clustering/kmeans?k=45&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 18:02:49,442 - Requested to get clustering details.
DEBUG admin 2020-07-15 18:02:49,442 - Reading datafile for clustered data
INFO admin 2020-07-15 18:02:49,442 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 18:02:49,450 - 127.0.0.1 - - [15/Jul/2020 18:02:49] "[37mGET /clustering/kmeans?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 18:02:49,543 - Requested to get clustering summary.
DEBUG admin 2020-07-15 18:02:49,543 - Reading datafile for clustering summary
INFO admin 2020-07-15 18:02:49,543 - Get request for clustering summary served successfully
DEBUG admin 2020-07-15 18:02:49,551 - Returning clustering details
INFO werkzeug 2020-07-15 18:02:49,551 - 127.0.0.1 - - [15/Jul/2020 18:02:49] "[37mGET /clustering/summary?uname=admin&content_type=clust HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:25:37,754 - Requested to extract data.
DEBUG admin 2020-07-15 19:25:37,754 - Extracted links and ISINs from JSON object.
INFO admin 2020-07-15 19:25:59,016 - Made entry for extracted data in datafile successfully.
INFO werkzeug 2020-07-15 19:25:59,017 - 127.0.0.1 - - [15/Jul/2020 19:25:59] "[37mPOST /extract?no_of_docs=30&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:26:37,650 - Requested to pre-process data.
DEBUG admin 2020-07-15 19:26:37,650 - Reading data from datafile
DEBUG admin 2020-07-15 19:26:37,661 - Pre-processing text data
DEBUG admin 2020-07-15 19:26:56,418 - Pre-processed data
DEBUG admin 2020-07-15 19:26:56,418 - Writting pre-processed data to datafile
DEBUG admin 2020-07-15 19:26:56,420 - Made entry of pre-processed data in datafile successfully
INFO werkzeug 2020-07-15 19:26:56,421 - 127.0.0.1 - - [15/Jul/2020 19:26:56] "[37mPOST /preprocess?steps=url&steps=stemming&steps=lemmatization&steps=stopwords&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:28:02,560 - Requested to pre-process data.
DEBUG admin 2020-07-15 19:28:02,561 - Reading data from datafile
DEBUG admin 2020-07-15 19:28:02,571 - Pre-processing text data
DEBUG admin 2020-07-15 19:28:20,149 - Pre-processed data
DEBUG admin 2020-07-15 19:28:20,149 - Writting pre-processed data to datafile
DEBUG admin 2020-07-15 19:28:20,151 - Made entry of pre-processed data in datafile successfully
INFO werkzeug 2020-07-15 19:28:20,152 - 127.0.0.1 - - [15/Jul/2020 19:28:20] "[37mPOST /preprocess?steps=url&steps=stemming&steps=lemmatization&steps=stopwords&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:28:48,893 - Requested to plot elbow curve.
DEBUG admin 2020-07-15 19:28:48,893 - Reading datafile..
DEBUG admin 2020-07-15 19:28:48,894 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 19:28:48,894 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 19:28:48,894 - Calculating tf-idf
DEBUG admin 2020-07-15 19:28:48,924 - Calculating variance threshold
DEBUG admin 2020-07-15 19:28:48,930 - Applying PCA
DEBUG admin 2020-07-15 19:28:49,399 - Plotting elbow curve
DEBUG admin 2020-07-15 19:28:53,280 - Writing optimal k value
INFO admin 2020-07-15 19:28:53,282 - Obtained optimal value of K using Elbow curve successfully
INFO werkzeug 2020-07-15 19:28:53,283 - 127.0.0.1 - - [15/Jul/2020 19:28:53] "[37mPOST /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:29:49,197 - Requested to get optimal k value
DEBUG admin 2020-07-15 19:29:49,197 - Reading datafile for optimal k value after elbow method
INFO admin 2020-07-15 19:29:49,197 - Get request for optimal k value served successfully
INFO werkzeug 2020-07-15 19:29:49,198 - 127.0.0.1 - - [15/Jul/2020 19:29:49] "[37mGET /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:30:14,946 - Requested for optimal value of K using Silhouette.
DEBUG admin 2020-07-15 19:30:14,947 - Reading datafile..
DEBUG admin 2020-07-15 19:30:14,947 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 19:30:14,948 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 19:30:14,948 - Calculating tf-idf
DEBUG admin 2020-07-15 19:30:14,983 - Calculating variance threshold
DEBUG admin 2020-07-15 19:30:14,992 - Applying PCA
DEBUG admin 2020-07-15 19:30:15,007 - Applying silhouette coefficient
DEBUG admin 2020-07-15 19:30:15,661 - Writting optimal k
INFO admin 2020-07-15 19:30:15,662 - Obtained optimal value of k using Silhouette score successfully
INFO werkzeug 2020-07-15 19:30:15,662 - 127.0.0.1 - - [15/Jul/2020 19:30:15] "[37mPOST /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:30:29,234 - Requested to get optimal k value
DEBUG admin 2020-07-15 19:30:29,234 - Reading datafile for optimal k value after silhouette
INFO admin 2020-07-15 19:30:29,234 - Get request for optimal k value served successfully
INFO werkzeug 2020-07-15 19:30:29,235 - 127.0.0.1 - - [15/Jul/2020 19:30:29] "[37mGET /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:30:59,942 - Requested to cluster documents.
DEBUG admin 2020-07-15 19:30:59,942 - Reading datafile..
DEBUG admin 2020-07-15 19:30:59,943 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-07-15 19:30:59,943 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-07-15 19:30:59,943 - Calculating tf-idf
DEBUG admin 2020-07-15 19:30:59,989 - Calculating variance threshold
DEBUG admin 2020-07-15 19:30:59,998 - Applying PCA
DEBUG admin 2020-07-15 19:31:00,019 - Applying K-Means algorithm
DEBUG admin 2020-07-15 19:31:00,042 - Sorting clusters
DEBUG admin 2020-07-15 19:31:00,043 - Converting to JSON format
DEBUG admin 2020-07-15 19:31:00,043 - Writting summary
DEBUG admin 2020-07-15 19:31:00,045 - Writting clustering information to datafile
INFO werkzeug 2020-07-15 19:31:00,046 - 127.0.0.1 - - [15/Jul/2020 19:31:00] "[37mPOST /clustering/kmeans?k=4&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:31:26,629 - Requested to get clustering details.
DEBUG admin 2020-07-15 19:31:26,629 - Reading datafile for clustered data
INFO admin 2020-07-15 19:31:26,630 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 19:31:26,631 - 127.0.0.1 - - [15/Jul/2020 19:31:26] "[37mGET /clustering/kmeans?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:32:11,721 - Requested to get clustering summary.
DEBUG admin 2020-07-15 19:32:11,722 - Reading datafile for clustering summary
INFO admin 2020-07-15 19:32:11,722 - Get request for clustering summary served successfully
DEBUG admin 2020-07-15 19:32:11,722 - Returning summary
INFO werkzeug 2020-07-15 19:32:11,723 - 127.0.0.1 - - [15/Jul/2020 19:32:11] "[37mGET /clustering/summary?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:32:26,352 - Requested to get clustering summary.
DEBUG admin 2020-07-15 19:32:26,353 - Reading datafile for clustering summary
INFO admin 2020-07-15 19:32:26,353 - Get request for clustering summary served successfully
DEBUG admin 2020-07-15 19:32:26,353 - Returning clustering details
INFO werkzeug 2020-07-15 19:32:26,354 - 127.0.0.1 - - [15/Jul/2020 19:32:26] "[37mGET /clustering/summary?uname=admin&content_type=clust HTTP/1.1[0m" 200 -
INFO admin 2020-07-15 19:34:04,466 - Requested to get clustering details.
DEBUG admin 2020-07-15 19:34:04,466 - Reading datafile for clustered data
INFO admin 2020-07-15 19:34:04,467 - Get request for clustered data served successfully
INFO werkzeug 2020-07-15 19:34:04,468 - 127.0.0.1 - - [15/Jul/2020 19:34:04] "[37mGET /clustering/kmeans?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:10,320 - Requested to extract data.
DEBUG admin 2020-08-28 21:18:10,367 - Extracted links and ISINs from JSON object.
INFO admin 2020-08-28 21:18:11,116 - Made entry for extracted data in datafile successfully.
INFO werkzeug 2020-08-28 21:18:11,116 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[37mPOST /extract?no_of_docs=30&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:11,156 - Requested to export extracted data.
DEBUG admin 2020-08-28 21:18:11,156 - Checking if filepath has valid format
DEBUG admin 2020-08-28 21:18:11,156 - Exporting data to excel file
INFO admin 2020-08-28 21:18:11,192 - Exported successfully
INFO werkzeug 2020-08-28 21:18:11,196 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[37mPOST /extract/export?filepath=extract.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:11,204 - Requested to pre-process data.
DEBUG admin 2020-08-28 21:18:11,204 - Reading data from datafile
DEBUG admin 2020-08-28 21:18:11,204 - Pre-processing text data
DEBUG admin 2020-08-28 21:18:11,204 - Pre-processed data
DEBUG admin 2020-08-28 21:18:11,204 - Writting pre-processed data to datafile
DEBUG admin 2020-08-28 21:18:11,204 - Made entry of pre-processed data in datafile successfully
INFO werkzeug 2020-08-28 21:18:11,208 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[37mPOST /preprocess?steps=url&steps=stemming&steps=lemmatization&steps=stopwords&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:11,216 - Requested to export pre-processed data.
DEBUG admin 2020-08-28 21:18:11,216 - Reading pre-processed datafile.
DEBUG admin 2020-08-28 21:18:11,216 - Exporting pre-processed data to excel file.
INFO admin 2020-08-28 21:18:11,256 - Exported pre-processed data successfully.
INFO werkzeug 2020-08-28 21:18:11,256 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[37mPOST /preprocess/export?filepath=prep.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:11,268 - Requested to plot elbow curve.
DEBUG admin 2020-08-28 21:18:11,268 - Reading datafile..
DEBUG admin 2020-08-28 21:18:11,268 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:11,268 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:11,268 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:11,272 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1314, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:11,291 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mPOST /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,291 - Requested to get optimal k value
DEBUG admin 2020-08-28 21:18:11,291 - Reading datafile for optimal k value after elbow method
INFO admin 2020-08-28 21:18:11,291 - Get request for optimal k value served successfully
ERROR admin 2020-08-28 21:18:11,291 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1372, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:11,322 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mGET /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,334 - Requested for optimal value of K using Silhouette.
DEBUG admin 2020-08-28 21:18:11,334 - Reading datafile..
DEBUG admin 2020-08-28 21:18:11,334 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:11,334 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:11,334 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:11,334 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1453, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:11,338 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mPOST /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,346 - Requested to get optimal k value
DEBUG admin 2020-08-28 21:18:11,346 - Reading datafile for optimal k value after silhouette
INFO admin 2020-08-28 21:18:11,346 - Get request for optimal k value served successfully
ERROR admin 2020-08-28 21:18:11,346 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1512, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:11,350 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mGET /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,358 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:18:11,358 - Reading datafile..
DEBUG admin 2020-08-28 21:18:11,358 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:11,358 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:11,358 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:11,358 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 560, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:11,362 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mPOST /clustering/kmeans?k=4&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,370 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:18:11,370 - Reading datafile for clustered data
INFO admin 2020-08-28 21:18:11,370 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:18:11,370 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 646, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:11,374 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mGET /clustering/kmeans?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,390 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:18:11,390 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:18:11,390 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:18:11,390 - Returning summary
ERROR admin 2020-08-28 21:18:11,390 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:11,390 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mGET /clustering/summary?uname=admin HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,426 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:18:11,426 - Reading datafile..
DEBUG admin 2020-08-28 21:18:11,426 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:11,426 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:11,426 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:11,426 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 736, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:11,430 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mPOST /clustering/dbscan?eps=0.3&min=1&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,442 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:18:11,442 - Reading datafile for clustered data
INFO admin 2020-08-28 21:18:11,442 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:18:11,442 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 823, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:11,446 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mGET /clustering/dbscan?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,462 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:18:11,462 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:18:11,462 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:18:11,462 - Returning summary
ERROR admin 2020-08-28 21:18:11,462 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:11,466 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,502 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:18:11,502 - Reading datafile..
DEBUG admin 2020-08-28 21:18:11,506 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:11,506 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:11,506 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:11,506 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 911, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:11,506 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mPOST /clustering/agglomerative?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,514 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:18:11,514 - Reading datafile for clustered data
INFO admin 2020-08-28 21:18:11,518 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:18:11,518 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 997, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:11,518 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mGET /clustering/agglomerative?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,534 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:18:11,534 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:18:11,534 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:18:11,538 - Returning summary
ERROR admin 2020-08-28 21:18:11,538 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:11,538 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,582 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:18:11,582 - Reading datafile..
DEBUG admin 2020-08-28 21:18:11,582 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:11,582 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:11,582 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:11,582 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1085, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:11,586 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mPOST /clustering/birch?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,602 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:18:11,602 - Reading datafile for clustered data
INFO admin 2020-08-28 21:18:11,602 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:18:11,602 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1171, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:11,606 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mGET /clustering/birch?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:11,642 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:18:11,646 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:18:11,646 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:18:11,646 - Returning summary
ERROR admin 2020-08-28 21:18:11,646 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:11,646 - 127.0.0.1 - - [28/Aug/2020 21:18:11] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO abcd 2020-08-28 21:18:11,682 - Requested for report generation.
DEBUG abcd 2020-08-28 21:18:11,682 - Checking for json input
DEBUG abcd 2020-08-28 21:18:11,682 - Fetching URLs
DEBUG abcd 2020-08-28 21:18:11,682 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007930/dp108304_424b2-us1972721.htm URL
ERROR abcd 2020-08-28 21:18:11,714 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007930/dp108304_424b2-us1972721.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:11,750 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008018/dp108385_424b2-us1972668.htm URL
ERROR abcd 2020-08-28 21:18:11,770 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319008018/dp108385_424b2-us1972668.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:11,774 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008084/dp108463_424b2-us1972667.htm URL
ERROR abcd 2020-08-28 21:18:11,794 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319008084/dp108463_424b2-us1972667.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:11,798 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009058/dp109430_424b2-us1972617.htm URL
ERROR abcd 2020-08-28 21:18:11,825 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009058/dp109430_424b2-us1972617.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:11,825 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007911/dp108280_424b2-us1972550.htm URL
ERROR abcd 2020-08-28 21:18:11,841 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007911/dp108280_424b2-us1972550.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:11,841 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009050/dp109447_424b2-us1972547.htm URL
ERROR abcd 2020-08-28 21:18:11,872 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009050/dp109447_424b2-us1972547.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:11,872 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007828/dp108206_424b2-us1972545.htm URL
ERROR abcd 2020-08-28 21:18:11,888 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007828/dp108206_424b2-us1972545.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:11,888 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009060/dp109497_424b2-us1972484.htm URL
ERROR abcd 2020-08-28 21:18:11,919 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009060/dp109497_424b2-us1972484.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:11,919 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007527/dp107872_fwp-us1972482.htm URL
ERROR abcd 2020-08-28 21:18:11,935 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007527/dp107872_fwp-us1972482.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:11,935 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007524/dp107870_fwp-us1972480.htm URL
ERROR abcd 2020-08-28 21:18:11,966 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007524/dp107870_fwp-us1972480.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:11,966 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008572/dp109026_424b2-us1972369.htm URL
ERROR abcd 2020-08-28 21:18:11,997 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319008572/dp109026_424b2-us1972369.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:11,997 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007525/dp107868_fwp-us1972350.htm URL
ERROR abcd 2020-08-28 21:18:12,028 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007525/dp107868_fwp-us1972350.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:12,028 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009080/dp109492_424b2-us1972281.htm URL
ERROR abcd 2020-08-28 21:18:12,044 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009080/dp109492_424b2-us1972281.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:12,060 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007870/dp108232_424b2-us1972280.htm URL
ERROR abcd 2020-08-28 21:18:12,075 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007870/dp108232_424b2-us1972280.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:12,075 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007155/dp107611_424b2-us1972269.htm URL
ERROR abcd 2020-08-28 21:18:12,107 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007155/dp107611_424b2-us1972269.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:12,107 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009048/dp109444_424b2-us1972158.htm URL
ERROR abcd 2020-08-28 21:18:12,122 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009048/dp109444_424b2-us1972158.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
INFO abcd 2020-08-28 21:18:12,122 - Report generation has started.
DEBUG abcd 2020-08-28 21:18:12,122 - Using bruteforce method for report generation
INFO werkzeug 2020-08-28 21:18:12,122 - 127.0.0.1 - - [28/Aug/2020 21:18:12] "[37mPOST /report?uname=abcd&kind=1 HTTP/1.1[0m" 200 -
INFO abcd 2020-08-28 21:18:12,216 - Requested for report generation.
DEBUG abcd 2020-08-28 21:18:12,216 - Searching for JSON Dump
ERROR abcd 2020-08-28 21:18:12,216 - Could not find the JSON Dump, the file is not prepared yet
INFO werkzeug 2020-08-28 21:18:12,220 - 127.0.0.1 - - [28/Aug/2020 21:18:12] "[31m[1mGET /report?uname=abcd HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:12,296 - Requested to get log file..
INFO admin 2020-08-28 21:18:12,296 - Sending log file
INFO werkzeug 2020-08-28 21:18:12,312 - 127.0.0.1 - - [28/Aug/2020 21:18:12] "[37mGET /getlog?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:12,340 - Requested to clear log file..
INFO admin 2020-08-28 21:18:12,340 - Cleared log file
INFO werkzeug 2020-08-28 21:18:12,340 - 127.0.0.1 - - [28/Aug/2020 21:18:12] "[37mDELETE /clearlog?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:49,117 - Requested to extract data.
DEBUG admin 2020-08-28 21:18:49,117 - Extracted links and ISINs from JSON object.
INFO admin 2020-08-28 21:18:49,929 - Made entry for extracted data in datafile successfully.
INFO werkzeug 2020-08-28 21:18:49,929 - 127.0.0.1 - - [28/Aug/2020 21:18:49] "[37mPOST /extract?no_of_docs=30&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:49,944 - Requested to export extracted data.
DEBUG admin 2020-08-28 21:18:49,944 - Checking if filepath has valid format
DEBUG admin 2020-08-28 21:18:49,944 - Exporting data to excel file
INFO admin 2020-08-28 21:18:49,991 - Exported successfully
INFO werkzeug 2020-08-28 21:18:49,991 - 127.0.0.1 - - [28/Aug/2020 21:18:49] "[37mPOST /extract/export?filepath=extract.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:50,007 - Requested to pre-process data.
DEBUG admin 2020-08-28 21:18:50,007 - Reading data from datafile
DEBUG admin 2020-08-28 21:18:50,007 - Pre-processing text data
DEBUG admin 2020-08-28 21:18:50,007 - Pre-processed data
DEBUG admin 2020-08-28 21:18:50,007 - Writting pre-processed data to datafile
DEBUG admin 2020-08-28 21:18:50,023 - Made entry of pre-processed data in datafile successfully
INFO werkzeug 2020-08-28 21:18:50,023 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[37mPOST /preprocess?steps=url&steps=stemming&steps=lemmatization&steps=stopwords&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:50,023 - Requested to export pre-processed data.
DEBUG admin 2020-08-28 21:18:50,038 - Reading pre-processed datafile.
DEBUG admin 2020-08-28 21:18:50,038 - Exporting pre-processed data to excel file.
INFO admin 2020-08-28 21:18:50,085 - Exported pre-processed data successfully.
INFO werkzeug 2020-08-28 21:18:50,085 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[37mPOST /preprocess/export?filepath=prep.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:50,101 - Requested to plot elbow curve.
DEBUG admin 2020-08-28 21:18:50,101 - Reading datafile..
DEBUG admin 2020-08-28 21:18:50,101 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:50,101 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:50,101 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:50,101 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1314, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:50,101 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mPOST /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,116 - Requested to get optimal k value
DEBUG admin 2020-08-28 21:18:50,116 - Reading datafile for optimal k value after elbow method
INFO admin 2020-08-28 21:18:50,116 - Get request for optimal k value served successfully
ERROR admin 2020-08-28 21:18:50,116 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1372, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:50,116 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mGET /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,155 - Requested for optimal value of K using Silhouette.
DEBUG admin 2020-08-28 21:18:50,156 - Reading datafile..
DEBUG admin 2020-08-28 21:18:50,157 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:50,157 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:50,158 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:50,158 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1453, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:50,159 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mPOST /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,174 - Requested to get optimal k value
DEBUG admin 2020-08-28 21:18:50,174 - Reading datafile for optimal k value after silhouette
INFO admin 2020-08-28 21:18:50,175 - Get request for optimal k value served successfully
ERROR admin 2020-08-28 21:18:50,175 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1512, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:50,176 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mGET /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,196 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:18:50,196 - Reading datafile..
DEBUG admin 2020-08-28 21:18:50,198 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:50,199 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:50,199 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:50,199 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 560, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:50,202 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mPOST /clustering/kmeans?k=4&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,217 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:18:50,218 - Reading datafile for clustered data
INFO admin 2020-08-28 21:18:50,219 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:18:50,219 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 646, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:50,219 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mGET /clustering/kmeans?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,235 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:18:50,235 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:18:50,235 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:18:50,235 - Returning summary
ERROR admin 2020-08-28 21:18:50,235 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:50,235 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mGET /clustering/summary?uname=admin HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,250 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:18:50,250 - Reading datafile..
DEBUG admin 2020-08-28 21:18:50,250 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:50,250 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:50,250 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:50,250 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 736, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:50,266 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mPOST /clustering/dbscan?eps=0.3&min=1&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,266 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:18:50,266 - Reading datafile for clustered data
INFO admin 2020-08-28 21:18:50,266 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:18:50,266 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 823, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:50,266 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mGET /clustering/dbscan?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,281 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:18:50,281 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:18:50,281 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:18:50,281 - Returning summary
ERROR admin 2020-08-28 21:18:50,281 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:50,297 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,297 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:18:50,297 - Reading datafile..
DEBUG admin 2020-08-28 21:18:50,297 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:50,297 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:50,297 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:50,297 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 911, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:50,297 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mPOST /clustering/agglomerative?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,313 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:18:50,313 - Reading datafile for clustered data
INFO admin 2020-08-28 21:18:50,313 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:18:50,313 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 997, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:50,313 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mGET /clustering/agglomerative?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,328 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:18:50,328 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:18:50,328 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:18:50,328 - Returning summary
ERROR admin 2020-08-28 21:18:50,328 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:50,328 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,344 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:18:50,344 - Reading datafile..
DEBUG admin 2020-08-28 21:18:50,344 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:18:50,344 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:18:50,344 - Calculating tf-idf
ERROR admin 2020-08-28 21:18:50,344 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1085, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:18:50,344 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mPOST /clustering/birch?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,360 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:18:50,360 - Reading datafile for clustered data
INFO admin 2020-08-28 21:18:50,360 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:18:50,360 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1171, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:50,360 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mGET /clustering/birch?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,375 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:18:50,375 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:18:50,375 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:18:50,375 - Returning summary
ERROR admin 2020-08-28 21:18:50,375 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:18:50,375 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO abcd 2020-08-28 21:18:50,391 - Requested for report generation.
DEBUG abcd 2020-08-28 21:18:50,391 - Checking for json input
DEBUG abcd 2020-08-28 21:18:50,391 - Fetching URLs
DEBUG abcd 2020-08-28 21:18:50,391 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007930/dp108304_424b2-us1972721.htm URL
ERROR abcd 2020-08-28 21:18:50,406 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007930/dp108304_424b2-us1972721.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,422 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008018/dp108385_424b2-us1972668.htm URL
ERROR abcd 2020-08-28 21:18:50,438 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319008018/dp108385_424b2-us1972668.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,438 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008084/dp108463_424b2-us1972667.htm URL
ERROR abcd 2020-08-28 21:18:50,469 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319008084/dp108463_424b2-us1972667.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,469 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009058/dp109430_424b2-us1972617.htm URL
ERROR abcd 2020-08-28 21:18:50,500 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009058/dp109430_424b2-us1972617.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,516 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007911/dp108280_424b2-us1972550.htm URL
ERROR abcd 2020-08-28 21:18:50,547 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007911/dp108280_424b2-us1972550.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,563 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009050/dp109447_424b2-us1972547.htm URL
ERROR abcd 2020-08-28 21:18:50,578 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009050/dp109447_424b2-us1972547.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,594 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007828/dp108206_424b2-us1972545.htm URL
ERROR abcd 2020-08-28 21:18:50,609 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007828/dp108206_424b2-us1972545.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,625 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009060/dp109497_424b2-us1972484.htm URL
ERROR abcd 2020-08-28 21:18:50,672 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009060/dp109497_424b2-us1972484.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,672 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007527/dp107872_fwp-us1972482.htm URL
ERROR abcd 2020-08-28 21:18:50,688 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007527/dp107872_fwp-us1972482.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,703 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007524/dp107870_fwp-us1972480.htm URL
ERROR abcd 2020-08-28 21:18:50,719 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007524/dp107870_fwp-us1972480.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,734 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008572/dp109026_424b2-us1972369.htm URL
ERROR abcd 2020-08-28 21:18:50,750 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319008572/dp109026_424b2-us1972369.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,766 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007525/dp107868_fwp-us1972350.htm URL
ERROR abcd 2020-08-28 21:18:50,781 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007525/dp107868_fwp-us1972350.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,781 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009080/dp109492_424b2-us1972281.htm URL
ERROR abcd 2020-08-28 21:18:50,813 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009080/dp109492_424b2-us1972281.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,813 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007870/dp108232_424b2-us1972280.htm URL
ERROR abcd 2020-08-28 21:18:50,844 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007870/dp108232_424b2-us1972280.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,844 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007155/dp107611_424b2-us1972269.htm URL
ERROR abcd 2020-08-28 21:18:50,875 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007155/dp107611_424b2-us1972269.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:18:50,875 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009048/dp109444_424b2-us1972158.htm URL
ERROR abcd 2020-08-28 21:18:50,906 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009048/dp109444_424b2-us1972158.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
INFO abcd 2020-08-28 21:18:50,906 - Report generation has started.
DEBUG abcd 2020-08-28 21:18:50,906 - Using bruteforce method for report generation
INFO werkzeug 2020-08-28 21:18:50,906 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[37mPOST /report?uname=abcd&kind=1 HTTP/1.1[0m" 200 -
INFO abcd 2020-08-28 21:18:50,922 - Requested for report generation.
DEBUG abcd 2020-08-28 21:18:50,922 - Searching for JSON Dump
ERROR abcd 2020-08-28 21:18:50,922 - Could not find the JSON Dump, the file is not prepared yet
INFO werkzeug 2020-08-28 21:18:50,922 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[31m[1mGET /report?uname=abcd HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:18:50,938 - Requested to get log file..
INFO admin 2020-08-28 21:18:50,938 - Sending log file
INFO werkzeug 2020-08-28 21:18:50,953 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[37mGET /getlog?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:18:50,953 - Requested to clear log file..
INFO admin 2020-08-28 21:18:50,953 - Cleared log file
INFO werkzeug 2020-08-28 21:18:50,953 - 127.0.0.1 - - [28/Aug/2020 21:18:50] "[37mDELETE /clearlog?uname=admin HTTP/1.1[0m" 200 -
INFO werkzeug 2020-08-28 21:21:06,735 -  * Detected change in 'C:\\Users\\ASHWIN\\Desktop\\FinIQ\\Assignments_FinIQ\\NLP_Citi\\pre-processing-and-API\\extract.py', reloading
INFO werkzeug 2020-08-28 21:21:07,028 -  * Restarting with stat
INFO werkzeug 2020-08-28 21:21:25,704 -  * Detected change in 'C:\\Users\\ASHWIN\\Desktop\\FinIQ\\Assignments_FinIQ\\NLP_Citi\\pre-processing-and-API\\extract.py', reloading
INFO werkzeug 2020-08-28 21:21:26,094 -  * Restarting with stat
INFO admin 2020-08-28 21:22:00,523 - Requested to extract data.
DEBUG admin 2020-08-28 21:22:00,538 - Extracted links and ISINs from JSON object.
INFO admin 2020-08-28 21:22:01,321 - Made entry for extracted data in datafile successfully.
INFO werkzeug 2020-08-28 21:22:01,321 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[37mPOST /extract?no_of_docs=30&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:22:01,347 - Requested to export extracted data.
DEBUG admin 2020-08-28 21:22:01,351 - Checking if filepath has valid format
DEBUG admin 2020-08-28 21:22:01,351 - Exporting data to excel file
INFO admin 2020-08-28 21:22:01,411 - Exported successfully
INFO werkzeug 2020-08-28 21:22:01,411 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[37mPOST /extract/export?filepath=extract.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:22:01,423 - Requested to pre-process data.
DEBUG admin 2020-08-28 21:22:01,423 - Reading data from datafile
DEBUG admin 2020-08-28 21:22:01,423 - Pre-processing text data
DEBUG admin 2020-08-28 21:22:01,423 - Pre-processed data
DEBUG admin 2020-08-28 21:22:01,423 - Writting pre-processed data to datafile
DEBUG admin 2020-08-28 21:22:01,423 - Made entry of pre-processed data in datafile successfully
INFO werkzeug 2020-08-28 21:22:01,427 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[37mPOST /preprocess?steps=url&steps=stemming&steps=lemmatization&steps=stopwords&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:22:01,439 - Requested to export pre-processed data.
DEBUG admin 2020-08-28 21:22:01,443 - Reading pre-processed datafile.
DEBUG admin 2020-08-28 21:22:01,443 - Exporting pre-processed data to excel file.
INFO admin 2020-08-28 21:22:01,490 - Exported pre-processed data successfully.
INFO werkzeug 2020-08-28 21:22:01,494 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[37mPOST /preprocess/export?filepath=prep.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:22:01,510 - Requested to plot elbow curve.
DEBUG admin 2020-08-28 21:22:01,510 - Reading datafile..
DEBUG admin 2020-08-28 21:22:01,510 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:22:01,510 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:22:01,510 - Calculating tf-idf
ERROR admin 2020-08-28 21:22:01,514 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1314, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:22:01,526 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mPOST /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,538 - Requested to get optimal k value
DEBUG admin 2020-08-28 21:22:01,538 - Reading datafile for optimal k value after elbow method
INFO admin 2020-08-28 21:22:01,538 - Get request for optimal k value served successfully
ERROR admin 2020-08-28 21:22:01,542 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1372, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 171, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:22:01,542 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mGET /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,566 - Requested for optimal value of K using Silhouette.
DEBUG admin 2020-08-28 21:22:01,566 - Reading datafile..
DEBUG admin 2020-08-28 21:22:01,566 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:22:01,566 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:22:01,566 - Calculating tf-idf
ERROR admin 2020-08-28 21:22:01,566 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1453, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:22:01,570 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mPOST /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,582 - Requested to get optimal k value
DEBUG admin 2020-08-28 21:22:01,582 - Reading datafile for optimal k value after silhouette
INFO admin 2020-08-28 21:22:01,586 - Get request for optimal k value served successfully
ERROR admin 2020-08-28 21:22:01,586 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1512, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 171, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:22:01,586 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mGET /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,606 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:22:01,606 - Reading datafile..
DEBUG admin 2020-08-28 21:22:01,606 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:22:01,606 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:22:01,606 - Calculating tf-idf
ERROR admin 2020-08-28 21:22:01,610 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 560, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:22:01,610 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mPOST /clustering/kmeans?k=4&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,641 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:22:01,641 - Reading datafile for clustered data
INFO admin 2020-08-28 21:22:01,642 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:22:01,642 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 646, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 171, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:22:01,644 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mGET /clustering/kmeans?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,670 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:22:01,670 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:22:01,674 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:22:01,674 - Returning summary
ERROR admin 2020-08-28 21:22:01,674 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 171, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:22:01,674 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mGET /clustering/summary?uname=admin HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,706 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:22:01,706 - Reading datafile..
DEBUG admin 2020-08-28 21:22:01,706 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:22:01,706 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:22:01,706 - Calculating tf-idf
ERROR admin 2020-08-28 21:22:01,706 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 736, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:22:01,710 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mPOST /clustering/dbscan?eps=0.3&min=1&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,726 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:22:01,726 - Reading datafile for clustered data
INFO admin 2020-08-28 21:22:01,726 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:22:01,726 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 823, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 171, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:22:01,726 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mGET /clustering/dbscan?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,754 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:22:01,754 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:22:01,754 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:22:01,758 - Returning summary
ERROR admin 2020-08-28 21:22:01,758 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 171, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:22:01,758 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,777 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:22:01,777 - Reading datafile..
DEBUG admin 2020-08-28 21:22:01,777 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:22:01,777 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:22:01,777 - Calculating tf-idf
ERROR admin 2020-08-28 21:22:01,777 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 911, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:22:01,781 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mPOST /clustering/agglomerative?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,797 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:22:01,797 - Reading datafile for clustered data
INFO admin 2020-08-28 21:22:01,797 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:22:01,801 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 997, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 171, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:22:01,801 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mGET /clustering/agglomerative?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,817 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:22:01,817 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:22:01,821 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:22:01,821 - Returning summary
ERROR admin 2020-08-28 21:22:01,821 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 171, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:22:01,825 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,841 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:22:01,841 - Reading datafile..
DEBUG admin 2020-08-28 21:22:01,841 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:22:01,841 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:22:01,845 - Calculating tf-idf
ERROR admin 2020-08-28 21:22:01,845 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1085, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:22:01,845 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mPOST /clustering/birch?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,861 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:22:01,861 - Reading datafile for clustered data
INFO admin 2020-08-28 21:22:01,861 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:22:01,861 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1171, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 171, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:22:01,865 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mGET /clustering/birch?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:01,905 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:22:01,905 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:22:01,905 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:22:01,905 - Returning summary
ERROR admin 2020-08-28 21:22:01,905 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 171, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:22:01,905 - 127.0.0.1 - - [28/Aug/2020 21:22:01] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO abcd 2020-08-28 21:22:01,933 - Requested for report generation.
DEBUG abcd 2020-08-28 21:22:01,937 - Checking for json input
DEBUG abcd 2020-08-28 21:22:01,937 - Fetching URLs
DEBUG abcd 2020-08-28 21:22:01,937 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007930/dp108304_424b2-us1972721.htm URL
ERROR abcd 2020-08-28 21:22:01,965 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007930/dp108304_424b2-us1972721.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:01,989 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008018/dp108385_424b2-us1972668.htm URL
ERROR abcd 2020-08-28 21:22:02,013 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319008018/dp108385_424b2-us1972668.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,017 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008084/dp108463_424b2-us1972667.htm URL
ERROR abcd 2020-08-28 21:22:02,037 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319008084/dp108463_424b2-us1972667.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,041 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009058/dp109430_424b2-us1972617.htm URL
ERROR abcd 2020-08-28 21:22:02,049 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009058/dp109430_424b2-us1972617.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,065 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007911/dp108280_424b2-us1972550.htm URL
ERROR abcd 2020-08-28 21:22:02,080 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007911/dp108280_424b2-us1972550.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,080 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009050/dp109447_424b2-us1972547.htm URL
ERROR abcd 2020-08-28 21:22:02,112 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009050/dp109447_424b2-us1972547.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,112 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007828/dp108206_424b2-us1972545.htm URL
ERROR abcd 2020-08-28 21:22:02,127 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007828/dp108206_424b2-us1972545.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,127 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009060/dp109497_424b2-us1972484.htm URL
ERROR abcd 2020-08-28 21:22:02,143 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009060/dp109497_424b2-us1972484.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,159 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007527/dp107872_fwp-us1972482.htm URL
ERROR abcd 2020-08-28 21:22:02,174 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007527/dp107872_fwp-us1972482.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,174 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007524/dp107870_fwp-us1972480.htm URL
ERROR abcd 2020-08-28 21:22:02,205 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007524/dp107870_fwp-us1972480.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,205 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008572/dp109026_424b2-us1972369.htm URL
ERROR abcd 2020-08-28 21:22:02,221 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319008572/dp109026_424b2-us1972369.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,221 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007525/dp107868_fwp-us1972350.htm URL
ERROR abcd 2020-08-28 21:22:02,252 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007525/dp107868_fwp-us1972350.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,252 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009080/dp109492_424b2-us1972281.htm URL
ERROR abcd 2020-08-28 21:22:02,268 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009080/dp109492_424b2-us1972281.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,268 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007870/dp108232_424b2-us1972280.htm URL
ERROR abcd 2020-08-28 21:22:02,299 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007870/dp108232_424b2-us1972280.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,315 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007155/dp107611_424b2-us1972269.htm URL
ERROR abcd 2020-08-28 21:22:02,330 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319007155/dp107611_424b2-us1972269.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
DEBUG abcd 2020-08-28 21:22:02,330 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009048/dp109444_424b2-us1972158.htm URL
ERROR abcd 2020-08-28 21:22:02,362 - The url: https://www.sec.gov/Archives/edgar/data/831001/000095010319009048/dp109444_424b2-us1972158.htm could not be fetched
Traceback (most recent call last):
  File "c:\python 3.8.2\lib\urllib\request.py", line 1319, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "c:\python 3.8.2\lib\http\client.py", line 1230, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1276, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1225, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "c:\python 3.8.2\lib\http\client.py", line 1004, in _send_output
    self.send(msg)
  File "c:\python 3.8.2\lib\http\client.py", line 944, in send
    self.connect()
  File "c:\python 3.8.2\lib\http\client.py", line 1392, in connect
    super().connect()
  File "c:\python 3.8.2\lib\http\client.py", line 915, in connect
    self.sock = self._create_connection(
  File "c:\python 3.8.2\lib\socket.py", line 787, in create_connection
    for res in getaddrinfo(host, port, 0, SOCK_STREAM):
  File "c:\python 3.8.2\lib\socket.py", line 918, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1698, in post
    html = urlopen(url).read()
  File "c:\python 3.8.2\lib\urllib\request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "c:\python 3.8.2\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "c:\python 3.8.2\lib\urllib\request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "c:\python 3.8.2\lib\urllib\request.py", line 502, in _call_chain
    result = func(*args)
  File "c:\python 3.8.2\lib\urllib\request.py", line 1362, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "c:\python 3.8.2\lib\urllib\request.py", line 1322, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error [Errno 11001] getaddrinfo failed>
INFO abcd 2020-08-28 21:22:02,362 - Report generation has started.
DEBUG abcd 2020-08-28 21:22:02,362 - Using bruteforce method for report generation
INFO werkzeug 2020-08-28 21:22:02,362 - 127.0.0.1 - - [28/Aug/2020 21:22:02] "[37mPOST /report?uname=abcd&kind=1 HTTP/1.1[0m" 200 -
INFO abcd 2020-08-28 21:22:02,399 - Requested for report generation.
DEBUG abcd 2020-08-28 21:22:02,399 - Searching for JSON Dump
ERROR abcd 2020-08-28 21:22:02,399 - Could not find the JSON Dump, the file is not prepared yet
INFO werkzeug 2020-08-28 21:22:02,399 - 127.0.0.1 - - [28/Aug/2020 21:22:02] "[31m[1mGET /report?uname=abcd HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:22:02,447 - Requested to get log file..
INFO admin 2020-08-28 21:22:02,451 - Sending log file
INFO werkzeug 2020-08-28 21:22:02,451 - 127.0.0.1 - - [28/Aug/2020 21:22:02] "[37mGET /getlog?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:22:02,495 - Requested to clear log file..
INFO admin 2020-08-28 21:22:02,495 - Cleared log file
INFO werkzeug 2020-08-28 21:22:02,499 - 127.0.0.1 - - [28/Aug/2020 21:22:02] "[37mDELETE /clearlog?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:22:41,864 - Requested to extract data.
DEBUG admin 2020-08-28 21:22:41,864 - Extracted links and ISINs from JSON object.
INFO admin 2020-08-28 21:22:42,482 - Made entry for extracted data in datafile successfully.
INFO werkzeug 2020-08-28 21:22:42,482 - 127.0.0.1 - - [28/Aug/2020 21:22:42] "[37mPOST /extract?no_of_docs=30&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO werkzeug 2020-08-28 21:24:03,927 -  * Detected change in 'C:\\Users\\ASHWIN\\Desktop\\FinIQ\\Assignments_FinIQ\\NLP_Citi\\pre-processing-and-API\\extract.py', reloading
INFO werkzeug 2020-08-28 21:24:04,241 -  * Restarting with stat
INFO admin 2020-08-28 21:25:45,966 - Requested to export extracted data.
DEBUG admin 2020-08-28 21:25:45,966 - Checking if filepath has valid format
DEBUG admin 2020-08-28 21:25:45,966 - Exporting data to excel file
INFO admin 2020-08-28 21:25:46,044 - Exported successfully
INFO werkzeug 2020-08-28 21:25:46,060 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[37mPOST /extract/export?filepath=extract.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:25:46,075 - Requested to pre-process data.
DEBUG admin 2020-08-28 21:25:46,075 - Reading data from datafile
DEBUG admin 2020-08-28 21:25:46,075 - Pre-processing text data
DEBUG admin 2020-08-28 21:25:46,075 - Pre-processed data
DEBUG admin 2020-08-28 21:25:46,075 - Writting pre-processed data to datafile
DEBUG admin 2020-08-28 21:25:46,075 - Made entry of pre-processed data in datafile successfully
INFO werkzeug 2020-08-28 21:25:46,075 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[37mPOST /preprocess?steps=url&steps=stemming&steps=lemmatization&steps=stopwords&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:25:46,107 - Requested to export pre-processed data.
DEBUG admin 2020-08-28 21:25:46,108 - Reading pre-processed datafile.
DEBUG admin 2020-08-28 21:25:46,108 - Exporting pre-processed data to excel file.
INFO admin 2020-08-28 21:25:46,230 - Exported pre-processed data successfully.
INFO werkzeug 2020-08-28 21:25:46,238 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[37mPOST /preprocess/export?filepath=prep.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:25:46,258 - Requested to plot elbow curve.
DEBUG admin 2020-08-28 21:25:46,258 - Reading datafile..
DEBUG admin 2020-08-28 21:25:46,262 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:25:46,262 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:25:46,262 - Calculating tf-idf
ERROR admin 2020-08-28 21:25:46,262 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1314, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:25:46,290 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mPOST /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,305 - Requested to get optimal k value
DEBUG admin 2020-08-28 21:25:46,305 - Reading datafile for optimal k value after elbow method
INFO admin 2020-08-28 21:25:46,305 - Get request for optimal k value served successfully
ERROR admin 2020-08-28 21:25:46,305 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1372, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:25:46,305 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mGET /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,321 - Requested for optimal value of K using Silhouette.
DEBUG admin 2020-08-28 21:25:46,321 - Reading datafile..
DEBUG admin 2020-08-28 21:25:46,337 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:25:46,337 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:25:46,337 - Calculating tf-idf
ERROR admin 2020-08-28 21:25:46,337 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1453, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:25:46,337 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mPOST /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,352 - Requested to get optimal k value
DEBUG admin 2020-08-28 21:25:46,352 - Reading datafile for optimal k value after silhouette
INFO admin 2020-08-28 21:25:46,352 - Get request for optimal k value served successfully
ERROR admin 2020-08-28 21:25:46,352 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1512, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:25:46,352 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mGET /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,384 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:25:46,384 - Reading datafile..
DEBUG admin 2020-08-28 21:25:46,384 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:25:46,384 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:25:46,384 - Calculating tf-idf
ERROR admin 2020-08-28 21:25:46,384 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 560, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:25:46,384 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mPOST /clustering/kmeans?k=4&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,399 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:25:46,399 - Reading datafile for clustered data
INFO admin 2020-08-28 21:25:46,399 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:25:46,399 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 646, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:25:46,415 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mGET /clustering/kmeans?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,430 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:25:46,430 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:25:46,430 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:25:46,430 - Returning summary
ERROR admin 2020-08-28 21:25:46,430 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:25:46,430 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mGET /clustering/summary?uname=admin HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,462 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:25:46,462 - Reading datafile..
DEBUG admin 2020-08-28 21:25:46,462 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:25:46,462 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:25:46,462 - Calculating tf-idf
ERROR admin 2020-08-28 21:25:46,462 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 736, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:25:46,462 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mPOST /clustering/dbscan?eps=0.3&min=1&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,477 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:25:46,477 - Reading datafile for clustered data
INFO admin 2020-08-28 21:25:46,493 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:25:46,493 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 823, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:25:46,493 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mGET /clustering/dbscan?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,508 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:25:46,508 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:25:46,508 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:25:46,508 - Returning summary
ERROR admin 2020-08-28 21:25:46,508 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:25:46,508 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,540 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:25:46,540 - Reading datafile..
DEBUG admin 2020-08-28 21:25:46,540 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:25:46,540 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:25:46,540 - Calculating tf-idf
ERROR admin 2020-08-28 21:25:46,540 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 911, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:25:46,540 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mPOST /clustering/agglomerative?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,571 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:25:46,571 - Reading datafile for clustered data
INFO admin 2020-08-28 21:25:46,571 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:25:46,571 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 997, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:25:46,571 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mGET /clustering/agglomerative?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,587 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:25:46,587 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:25:46,587 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:25:46,602 - Returning summary
ERROR admin 2020-08-28 21:25:46,603 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:25:46,603 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,627 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:25:46,631 - Reading datafile..
DEBUG admin 2020-08-28 21:25:46,631 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:25:46,635 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:25:46,635 - Calculating tf-idf
ERROR admin 2020-08-28 21:25:46,635 - Exception occurred: ValueError('empty vocabulary; perhaps the documents only contain stop words')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1085, in post
    df = cf.tfidf(text)
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\clean_file.py", line 172, in tfidf
    vectors = vectorizer.fit_transform(text)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1840, in fit_transform
    X = super().fit_transform(raw_documents)
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1198, in fit_transform
    vocabulary, X = self._count_vocab(raw_documents,
  File "c:\python 3.8.2\lib\site-packages\sklearn\feature_extraction\text.py", line 1129, in _count_vocab
    raise ValueError("empty vocabulary; perhaps the documents only"
ValueError: empty vocabulary; perhaps the documents only contain stop words
INFO werkzeug 2020-08-28 21:25:46,639 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mPOST /clustering/birch?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,655 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:25:46,655 - Reading datafile for clustered data
INFO admin 2020-08-28 21:25:46,655 - Get request for clustered data served successfully
ERROR admin 2020-08-28 21:25:46,655 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1171, in get
    'data':ex.read_json(data),
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:25:46,671 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mGET /clustering/birch?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:25:46,687 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:25:46,687 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:25:46,687 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:25:46,687 - Returning summary
ERROR admin 2020-08-28 21:25:46,687 - Exception occurred: FileNotFoundError(2, 'No such file or directory')
Traceback (most recent call last):
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\api.py", line 1225, in get
    'data':ex.read_json(data)['summary'],
  File "C:\Users\ASHWIN\Desktop\FinIQ\Assignments_FinIQ\NLP_Citi\pre-processing-and-API\extract.py", line 174, in read_json
    fhand = open(fname)
FileNotFoundError: [Errno 2] No such file or directory: 'False'
INFO werkzeug 2020-08-28 21:25:46,687 - 127.0.0.1 - - [28/Aug/2020 21:25:46] "[31m[1mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 400 -
INFO abcd 2020-08-28 21:25:46,718 - Requested for report generation.
DEBUG abcd 2020-08-28 21:25:46,718 - Checking for json input
DEBUG abcd 2020-08-28 21:25:46,718 - Fetching URLs
DEBUG abcd 2020-08-28 21:25:46,718 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007930/dp108304_424b2-us1972721.htm URL
DEBUG abcd 2020-08-28 21:25:48,764 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008018/dp108385_424b2-us1972668.htm URL
DEBUG abcd 2020-08-28 21:25:51,221 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008084/dp108463_424b2-us1972667.htm URL
DEBUG abcd 2020-08-28 21:25:52,348 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009058/dp109430_424b2-us1972617.htm URL
DEBUG abcd 2020-08-28 21:25:54,618 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007911/dp108280_424b2-us1972550.htm URL
DEBUG abcd 2020-08-28 21:25:57,078 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009050/dp109447_424b2-us1972547.htm URL
DEBUG abcd 2020-08-28 21:25:58,721 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007828/dp108206_424b2-us1972545.htm URL
DEBUG abcd 2020-08-28 21:26:00,929 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009060/dp109497_424b2-us1972484.htm URL
DEBUG abcd 2020-08-28 21:26:02,700 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007527/dp107872_fwp-us1972482.htm URL
DEBUG abcd 2020-08-28 21:26:03,761 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007524/dp107870_fwp-us1972480.htm URL
DEBUG abcd 2020-08-28 21:26:05,204 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008572/dp109026_424b2-us1972369.htm URL
DEBUG abcd 2020-08-28 21:26:07,253 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007525/dp107868_fwp-us1972350.htm URL
DEBUG abcd 2020-08-28 21:26:08,159 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009080/dp109492_424b2-us1972281.htm URL
DEBUG abcd 2020-08-28 21:26:09,644 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007870/dp108232_424b2-us1972280.htm URL
DEBUG abcd 2020-08-28 21:26:11,815 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007155/dp107611_424b2-us1972269.htm URL
DEBUG abcd 2020-08-28 21:26:12,956 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009048/dp109444_424b2-us1972158.htm URL
INFO abcd 2020-08-28 21:26:15,146 - Report generation has started.
DEBUG abcd 2020-08-28 21:26:15,162 - Using bruteforce method for report generation
INFO werkzeug 2020-08-28 21:26:15,162 - 127.0.0.1 - - [28/Aug/2020 21:26:15] "[37mPOST /report?uname=abcd&kind=1 HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:26:17,677 - Requested to extract data.
DEBUG admin 2020-08-28 21:26:17,677 - Extracted links and ISINs from JSON object.
INFO abcd 2020-08-28 21:26:19,739 - Report generated successfully
INFO admin 2020-08-28 21:26:49,693 - Made entry for extracted data in datafile successfully.
INFO werkzeug 2020-08-28 21:26:49,693 - 127.0.0.1 - - [28/Aug/2020 21:26:49] "[37mPOST /extract?no_of_docs=30&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:26:49,709 - Requested to export extracted data.
DEBUG admin 2020-08-28 21:26:49,724 - Checking if filepath has valid format
DEBUG admin 2020-08-28 21:26:49,724 - Exporting data to excel file
INFO admin 2020-08-28 21:26:49,865 - Exported successfully
INFO werkzeug 2020-08-28 21:26:49,865 - 127.0.0.1 - - [28/Aug/2020 21:26:49] "[37mPOST /extract/export?filepath=extract.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:26:49,865 - Requested to pre-process data.
DEBUG admin 2020-08-28 21:26:49,865 - Reading data from datafile
DEBUG admin 2020-08-28 21:26:49,881 - Pre-processing text data
DEBUG admin 2020-08-28 21:27:11,515 - Pre-processed data
DEBUG admin 2020-08-28 21:27:11,515 - Writting pre-processed data to datafile
DEBUG admin 2020-08-28 21:27:11,515 - Made entry of pre-processed data in datafile successfully
INFO werkzeug 2020-08-28 21:27:11,515 - 127.0.0.1 - - [28/Aug/2020 21:27:11] "[37mPOST /preprocess?steps=url&steps=stemming&steps=lemmatization&steps=stopwords&steps=unusual&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:11,531 - Requested to export pre-processed data.
DEBUG admin 2020-08-28 21:27:11,531 - Reading pre-processed datafile.
DEBUG admin 2020-08-28 21:27:11,547 - Exporting pre-processed data to excel file.
INFO admin 2020-08-28 21:27:11,593 - Exported pre-processed data successfully.
INFO werkzeug 2020-08-28 21:27:11,593 - 127.0.0.1 - - [28/Aug/2020 21:27:11] "[37mPOST /preprocess/export?filepath=prep.xlsx&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:11,609 - Requested to plot elbow curve.
DEBUG admin 2020-08-28 21:27:11,609 - Reading datafile..
DEBUG admin 2020-08-28 21:27:11,609 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:27:11,609 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:27:11,609 - Calculating tf-idf
DEBUG admin 2020-08-28 21:27:11,875 - Calculating variance threshold
DEBUG admin 2020-08-28 21:27:11,938 - Applying PCA
DEBUG admin 2020-08-28 21:27:12,082 - Plotting elbow curve
DEBUG admin 2020-08-28 21:27:14,993 - Writing optimal k value
INFO admin 2020-08-28 21:27:14,993 - Obtained optimal value of K using Elbow curve successfully
INFO werkzeug 2020-08-28 21:27:14,993 - 127.0.0.1 - - [28/Aug/2020 21:27:14] "[37mPOST /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:15,009 - Requested to get optimal k value
DEBUG admin 2020-08-28 21:27:15,009 - Reading datafile for optimal k value after elbow method
INFO admin 2020-08-28 21:27:15,009 - Get request for optimal k value served successfully
INFO werkzeug 2020-08-28 21:27:15,009 - 127.0.0.1 - - [28/Aug/2020 21:27:15] "[37mGET /clustering/elbow?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:15,009 - Requested for optimal value of K using Silhouette.
DEBUG admin 2020-08-28 21:27:15,009 - Reading datafile..
DEBUG admin 2020-08-28 21:27:15,009 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:27:15,009 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:27:15,009 - Calculating tf-idf
DEBUG admin 2020-08-28 21:27:15,056 - Calculating variance threshold
DEBUG admin 2020-08-28 21:27:15,056 - Applying PCA
DEBUG admin 2020-08-28 21:27:15,087 - Applying silhouette coefficient
DEBUG admin 2020-08-28 21:27:16,383 - Writting optimal k
INFO admin 2020-08-28 21:27:16,383 - Obtained optimal value of k using Silhouette score successfully
INFO werkzeug 2020-08-28 21:27:16,383 - 127.0.0.1 - - [28/Aug/2020 21:27:16] "[37mPOST /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:16,399 - Requested to get optimal k value
DEBUG admin 2020-08-28 21:27:16,399 - Reading datafile for optimal k value after silhouette
INFO admin 2020-08-28 21:27:16,399 - Get request for optimal k value served successfully
INFO werkzeug 2020-08-28 21:27:16,399 - 127.0.0.1 - - [28/Aug/2020 21:27:16] "[37mGET /clustering/silhouette?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:16,415 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:27:16,415 - Reading datafile..
DEBUG admin 2020-08-28 21:27:16,415 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:27:16,415 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:27:16,415 - Calculating tf-idf
DEBUG admin 2020-08-28 21:27:16,462 - Calculating variance threshold
DEBUG admin 2020-08-28 21:27:16,477 - Applying PCA
DEBUG admin 2020-08-28 21:27:16,508 - Applying K-Means algorithm
DEBUG admin 2020-08-28 21:27:16,555 - Sorting clusters
DEBUG admin 2020-08-28 21:27:16,555 - Converting to JSON format
DEBUG admin 2020-08-28 21:27:16,571 - Writting summary
DEBUG admin 2020-08-28 21:27:16,571 - Writting clustering information to datafile
INFO werkzeug 2020-08-28 21:27:16,571 - 127.0.0.1 - - [28/Aug/2020 21:27:16] "[37mPOST /clustering/kmeans?k=4&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:16,587 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:27:16,587 - Reading datafile for clustered data
INFO admin 2020-08-28 21:27:16,587 - Get request for clustered data served successfully
INFO werkzeug 2020-08-28 21:27:16,587 - 127.0.0.1 - - [28/Aug/2020 21:27:16] "[37mGET /clustering/kmeans?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:16,618 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:27:16,618 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:27:16,618 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:27:16,618 - Returning summary
INFO werkzeug 2020-08-28 21:27:16,618 - 127.0.0.1 - - [28/Aug/2020 21:27:16] "[37mGET /clustering/summary?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:16,633 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:27:16,633 - Reading datafile..
DEBUG admin 2020-08-28 21:27:16,633 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:27:16,633 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:27:16,633 - Calculating tf-idf
DEBUG admin 2020-08-28 21:27:16,696 - Calculating variance threshold
DEBUG admin 2020-08-28 21:27:16,711 - Applying PCA
DEBUG admin 2020-08-28 21:27:16,743 - Applying DBSCAN algorithm
DEBUG admin 2020-08-28 21:27:16,758 - Sorting clusters
DEBUG admin 2020-08-28 21:27:16,758 - Converting to JSON format
DEBUG admin 2020-08-28 21:27:16,758 - Writting summary
DEBUG admin 2020-08-28 21:27:16,758 - Writting clustering information to datafile
INFO werkzeug 2020-08-28 21:27:16,758 - 127.0.0.1 - - [28/Aug/2020 21:27:16] "[37mPOST /clustering/dbscan?eps=0.3&min=1&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:16,774 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:27:16,774 - Reading datafile for clustered data
INFO admin 2020-08-28 21:27:16,774 - Get request for clustered data served successfully
INFO werkzeug 2020-08-28 21:27:16,774 - 127.0.0.1 - - [28/Aug/2020 21:27:16] "[37mGET /clustering/dbscan?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:16,790 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:27:16,790 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:27:16,790 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:27:16,805 - Returning summary
INFO werkzeug 2020-08-28 21:27:16,805 - 127.0.0.1 - - [28/Aug/2020 21:27:16] "[37mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:16,821 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:27:16,821 - Reading datafile..
DEBUG admin 2020-08-28 21:27:16,821 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:27:16,821 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:27:16,821 - Calculating tf-idf
DEBUG admin 2020-08-28 21:27:16,868 - Calculating variance threshold
DEBUG admin 2020-08-28 21:27:16,883 - Applying PCA
DEBUG admin 2020-08-28 21:27:16,915 - Applying Agglomerative algorithm
DEBUG admin 2020-08-28 21:27:16,961 - Sorting clusters
DEBUG admin 2020-08-28 21:27:16,961 - Converting to JSON format
DEBUG admin 2020-08-28 21:27:16,961 - Writting summary
DEBUG admin 2020-08-28 21:27:16,961 - Writting clustering information to datafile
INFO werkzeug 2020-08-28 21:27:16,977 - 127.0.0.1 - - [28/Aug/2020 21:27:16] "[37mPOST /clustering/agglomerative?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:16,993 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:27:16,993 - Reading datafile for clustered data
INFO admin 2020-08-28 21:27:16,993 - Get request for clustered data served successfully
INFO werkzeug 2020-08-28 21:27:16,993 - 127.0.0.1 - - [28/Aug/2020 21:27:16] "[37mGET /clustering/agglomerative?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:17,024 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:27:17,024 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:27:17,024 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:27:17,024 - Returning summary
INFO werkzeug 2020-08-28 21:27:17,024 - 127.0.0.1 - - [28/Aug/2020 21:27:17] "[37mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:17,055 - Requested to cluster documents.
DEBUG admin 2020-08-28 21:27:17,055 - Reading datafile..
DEBUG admin 2020-08-28 21:27:17,055 - Setting default value of threshold for Variance Threshold to 0.0001
DEBUG admin 2020-08-28 21:27:17,055 - Setting default value of number of components for PCA to 0.8
DEBUG admin 2020-08-28 21:27:17,055 - Calculating tf-idf
DEBUG admin 2020-08-28 21:27:17,149 - Calculating variance threshold
DEBUG admin 2020-08-28 21:27:17,149 - Applying PCA
DEBUG admin 2020-08-28 21:27:17,180 - Applying Birch algorithm
DEBUG admin 2020-08-28 21:27:17,196 - Sorting clusters
DEBUG admin 2020-08-28 21:27:17,196 - Converting to JSON format
DEBUG admin 2020-08-28 21:27:17,196 - Writting summary
DEBUG admin 2020-08-28 21:27:17,196 - Writting clustering information to datafile
INFO werkzeug 2020-08-28 21:27:17,211 - 127.0.0.1 - - [28/Aug/2020 21:27:17] "[37mPOST /clustering/birch?k=5&format=csv&uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:17,211 - Requested to get clustering details.
DEBUG admin 2020-08-28 21:27:17,211 - Reading datafile for clustered data
INFO admin 2020-08-28 21:27:17,211 - Get request for clustered data served successfully
INFO werkzeug 2020-08-28 21:27:17,227 - 127.0.0.1 - - [28/Aug/2020 21:27:17] "[37mGET /clustering/birch?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:17,243 - Requested to get clustering summary.
DEBUG admin 2020-08-28 21:27:17,243 - Reading datafile for clustering summary
INFO admin 2020-08-28 21:27:17,243 - Get request for clustering summary served successfully
DEBUG admin 2020-08-28 21:27:17,243 - Returning summary
INFO werkzeug 2020-08-28 21:27:17,243 - 127.0.0.1 - - [28/Aug/2020 21:27:17] "[37mGET /clustering/summary?uname=admin&fname=ISINS_v3.xlsx HTTP/1.1[0m" 200 -
INFO abcd 2020-08-28 21:27:17,258 - Requested for report generation.
INFO abcd 2020-08-28 21:27:17,258 - Older JSON Dump for abcd has been deleted
DEBUG abcd 2020-08-28 21:27:17,258 - Checking for json input
DEBUG abcd 2020-08-28 21:27:17,258 - Fetching URLs
DEBUG abcd 2020-08-28 21:27:17,274 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007930/dp108304_424b2-us1972721.htm URL
DEBUG abcd 2020-08-28 21:27:17,946 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008018/dp108385_424b2-us1972668.htm URL
DEBUG abcd 2020-08-28 21:27:18,581 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008084/dp108463_424b2-us1972667.htm URL
DEBUG abcd 2020-08-28 21:27:19,125 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009058/dp109430_424b2-us1972617.htm URL
DEBUG abcd 2020-08-28 21:27:19,640 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007911/dp108280_424b2-us1972550.htm URL
DEBUG abcd 2020-08-28 21:27:20,203 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009050/dp109447_424b2-us1972547.htm URL
DEBUG abcd 2020-08-28 21:27:20,781 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007828/dp108206_424b2-us1972545.htm URL
DEBUG abcd 2020-08-28 21:27:21,296 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009060/dp109497_424b2-us1972484.htm URL
DEBUG abcd 2020-08-28 21:27:21,890 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007527/dp107872_fwp-us1972482.htm URL
DEBUG abcd 2020-08-28 21:27:22,218 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007524/dp107870_fwp-us1972480.htm URL
DEBUG abcd 2020-08-28 21:27:22,530 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319008572/dp109026_424b2-us1972369.htm URL
DEBUG abcd 2020-08-28 21:27:23,144 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007525/dp107868_fwp-us1972350.htm URL
DEBUG abcd 2020-08-28 21:27:23,539 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009080/dp109492_424b2-us1972281.htm URL
DEBUG abcd 2020-08-28 21:27:24,427 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007870/dp108232_424b2-us1972280.htm URL
DEBUG abcd 2020-08-28 21:27:25,411 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319007155/dp107611_424b2-us1972269.htm URL
DEBUG abcd 2020-08-28 21:27:25,958 - Fetching https://www.sec.gov/Archives/edgar/data/831001/000095010319009048/dp109444_424b2-us1972158.htm URL
INFO abcd 2020-08-28 21:27:26,583 - Report generation has started.
DEBUG abcd 2020-08-28 21:27:26,583 - Using bruteforce method for report generation
INFO werkzeug 2020-08-28 21:27:26,583 - 127.0.0.1 - - [28/Aug/2020 21:27:26] "[37mPOST /report?uname=abcd&kind=1 HTTP/1.1[0m" 200 -
INFO abcd 2020-08-28 21:27:26,629 - Requested for report generation.
DEBUG abcd 2020-08-28 21:27:26,629 - Searching for JSON Dump
ERROR abcd 2020-08-28 21:27:26,629 - Could not find the JSON Dump, the file is not prepared yet
INFO werkzeug 2020-08-28 21:27:26,645 - 127.0.0.1 - - [28/Aug/2020 21:27:26] "[31m[1mGET /report?uname=abcd HTTP/1.1[0m" 400 -
INFO admin 2020-08-28 21:27:26,676 - Requested to get log file..
INFO admin 2020-08-28 21:27:26,676 - Sending log file
INFO werkzeug 2020-08-28 21:27:26,692 - 127.0.0.1 - - [28/Aug/2020 21:27:26] "[37mGET /getlog?uname=admin HTTP/1.1[0m" 200 -
INFO admin 2020-08-28 21:27:26,692 - Requested to clear log file..
INFO admin 2020-08-28 21:27:26,692 - Cleared log file
INFO werkzeug 2020-08-28 21:27:26,692 - 127.0.0.1 - - [28/Aug/2020 21:27:26] "[37mDELETE /clearlog?uname=admin HTTP/1.1[0m" 200 -
INFO abcd 2020-08-28 21:27:29,316 - Report generated successfully
